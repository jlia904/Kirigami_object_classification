{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8cbb8b46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dell/Desktop/xxxx/Uni/Kirigami_project/Keypoint_detection_notebooks/.Keypoint_detection_notebooks/lib/python3.8/site-packages/requests/__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.14) or chardet (5.1.0)/charset_normalizer (2.0.12) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "# importing relevant packages \n",
    "\n",
    "import torch \n",
    "from torchvision import models\n",
    "import pandas as pd\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn \n",
    "import glob\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt \n",
    "import torchvision.transforms as transforms\n",
    "from torchsummary import summary\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from PIL import Image\n",
    "import random\n",
    "import albumentations as A\n",
    "import glob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a2a79d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VGG_model, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.LeakyReLU(0.1,inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.LeakyReLU(0.1,inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
    "            nn.Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.LeakyReLU(0.1,inplace=True),\n",
    "            nn.Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.LeakyReLU(0.1,inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
    "            nn.Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.LeakyReLU(0.1,inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.LeakyReLU(0.1,inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.LeakyReLU(0.1,inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
    "            nn.Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.LeakyReLU(0.1,inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.LeakyReLU(0.1,inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.LeakyReLU(0.1,inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
    "            nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.LeakyReLU(0.1,inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.LeakyReLU(0.1,inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "        )\n",
    "        \n",
    "        self.avgpool = nn.Sequential(\n",
    "            nn.Conv2d(512,512, kernel_size=3, padding='same'),\n",
    "            nn.LeakyReLU(0.1,inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(512,50, kernel_size=3, padding='same'),\n",
    "            nn.LeakyReLU(0.1,inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.AdaptiveAvgPool2d(output_size=(8,8))\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(3200, 300),\n",
    "            nn.LeakyReLU(0.1,inplace=True),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(300, 32),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3daa8a88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG_model(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): Sequential(\n",
       "    (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "    (1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(512, 50, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "    (4): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): AdaptiveAvgPool2d(output_size=(8, 8))\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=3200, out_features=300, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    (2): Dropout(p=0.3, inplace=False)\n",
       "    (3): Linear(in_features=300, out_features=32, bias=True)\n",
       "    (4): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = VGG_model()\n",
    "model.load_state_dict(torch.load('./Model_VGG_4_5_6_2000_16300_epoch'))\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = model.to(device)\n",
    "# model.train()\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0d4f2ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_keypoints(img):\n",
    "    img = cv2.resize(img, (224,224))\n",
    "    img_tensor = transforms.ToTensor()(img)\n",
    "    img_mean = img_tensor.mean(dim = (1,2))\n",
    "    img_std = img_tensor.std(dim = (1,2))\n",
    "        \n",
    "    img_normalised = transforms.Normalize(img_mean, img_std)(img_tensor)\n",
    "    img_normalised = img_normalised.to(device)\n",
    "    \n",
    "    key_points = model(img_normalised[None]).flatten().detach().cpu().numpy()\n",
    "    \n",
    "    return key_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "967d6f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_keypoints(img, keypoints):                                                             \n",
    "\n",
    "    plt.imshow(img)\n",
    "\n",
    "    x_points = keypoints[0::2]\n",
    "    y_points = keypoints[1::2]\n",
    "    plt.scatter(x_points*img.shape[1], y_points*img.shape[0], s = 4, c=(1,0,0))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "337c9168",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_names = ['Grasp_dataset_cylinder_20', 'Grasp_dataset_cylinder_40', 'Grasp_dataset_cylinder_60', 'Grasp_dataset_square_20', 'Grasp_dataset_square_40', 'Grasp_dataset_square_60']\n",
    "# header = ['pressure_reading_1', 'pressure_reading_2', 'force_reading_1', 'force_reading_2', 'p1_x', 'p1_y', 'p2_x', 'p2_y', 'p3_x', 'p3_y', 'p4_x', 'p4_y', 'p5_x', 'p5_y', 'p6_x', 'p6_y', 'p7_x', 'p7_y', 'p8_x', 'p8_y', 'p9_x', 'p9_y', 'p10_x', 'p10_y', 'p11_x', 'p11_y', 'p12_x', 'p12_y', 'p13_x', 'p13_y', 'p14_x', 'p14_y', 'p15_x', 'p15_y', 'p16_x', 'p16_y', 'label']\n",
    "header = ['pressure_reading_1', 'pressure_reading_2', 'p1_x', 'p1_y', 'p2_x', 'p2_y', 'p3_x', 'p3_y', 'p4_x', 'p4_y', 'p5_x', 'p5_y', 'p6_x', 'p6_y', 'p7_x', 'p7_y', 'p8_x', 'p8_y', 'p9_x', 'p9_y', 'p10_x', 'p10_y', 'p11_x', 'p11_y', 'p12_x', 'p12_y', 'p13_x', 'p13_y', 'p14_x', 'p14_y', 'p15_x', 'p15_y', 'p16_x', 'p16_y', 'label']\n",
    "\n",
    "current_dir = os. getcwd()\n",
    "\n",
    "pressure_reading_1_arr = []\n",
    "pressure_reading_2_arr = []\n",
    "# force_reading_1_arr = []\n",
    "# force_reading_2_arr = []\n",
    "\n",
    "p1_x_arr = []\n",
    "p1_y_arr = []\n",
    "p2_x_arr = []\n",
    "p2_y_arr = []\n",
    "p3_x_arr = []\n",
    "p3_y_arr = []\n",
    "p4_x_arr = []\n",
    "p4_y_arr = []\n",
    "p5_x_arr = []\n",
    "p5_y_arr = []\n",
    "p6_x_arr = []\n",
    "p6_y_arr = []\n",
    "p7_x_arr = []\n",
    "p7_y_arr = []\n",
    "p8_x_arr = []\n",
    "p8_y_arr = []\n",
    "p9_x_arr = []\n",
    "p9_y_arr = []\n",
    "p10_x_arr = []\n",
    "p10_y_arr = []\n",
    "p11_x_arr = []\n",
    "p11_y_arr = []\n",
    "p12_x_arr = []\n",
    "p12_y_arr = []\n",
    "p13_x_arr = []\n",
    "p13_y_arr = []\n",
    "p14_x_arr = []\n",
    "p14_y_arr = []\n",
    "p15_x_arr = []\n",
    "p15_y_arr = []\n",
    "p16_x_arr = []\n",
    "p16_y_arr = []\n",
    "label_arr = []\n",
    "\n",
    "\n",
    "for f in dataset_names:\n",
    "    \n",
    "    image_dir = os.path.join(current_dir + '/Grasp_dataset_2', f)\n",
    "    data_dir = os.path.join(image_dir, f + '.csv')\n",
    "    df = pd.read_csv(data_dir)\n",
    "    pressure_reading_1_arr = np.concatenate((pressure_reading_1_arr, df['pressure_reading_1'].values))\n",
    "    pressure_reading_2_arr = np.concatenate((pressure_reading_2_arr, df['pressure_reading_2'].values))\n",
    "#     force_reading_1_arr = np.concatenate((force_reading_1_arr, df['force_reading_1'].values))\n",
    "#     force_reading_2_arr = np.concatenate((force_reading_2_arr, df['force_reading_2'].values))\n",
    "    label_arr = np.concatenate((label_arr, df['label'].values))\n",
    "    \n",
    "    j = 0\n",
    "    \n",
    "    while j < df.shape[0]:\n",
    "        image = cv2.imread(os.path.join(image_dir, df.iloc[j]['image_name']))\n",
    "        keypoints = predict_keypoints(image)\n",
    "        \n",
    "#         plot_keypoints(image, keypoints)\n",
    "        \n",
    "#         if j == 20:\n",
    "#             plot_keypoints(image, keypoints)\n",
    "        \n",
    "        p1_x_arr.append(keypoints[0])\n",
    "        p1_y_arr.append(keypoints[1])\n",
    "        p2_x_arr.append(keypoints[2])\n",
    "        p2_y_arr.append(keypoints[3])\n",
    "        p3_x_arr.append(keypoints[4])\n",
    "        p3_y_arr.append(keypoints[5])\n",
    "        p4_x_arr.append(keypoints[6])\n",
    "        p4_y_arr.append(keypoints[7])\n",
    "        p5_x_arr.append(keypoints[8])\n",
    "        p5_y_arr.append(keypoints[9])\n",
    "        p6_x_arr.append(keypoints[10])\n",
    "        p6_y_arr.append(keypoints[11])\n",
    "        p7_x_arr.append(keypoints[12])\n",
    "        p7_y_arr.append(keypoints[13])\n",
    "        p8_x_arr.append(keypoints[14])\n",
    "        p8_y_arr.append(keypoints[15])\n",
    "        p9_x_arr.append(keypoints[16])\n",
    "        p9_y_arr.append(keypoints[17])\n",
    "        p10_x_arr.append(keypoints[18])\n",
    "        p10_y_arr.append(keypoints[19])\n",
    "        p11_x_arr.append(keypoints[20])\n",
    "        p11_y_arr.append(keypoints[21])\n",
    "        p12_x_arr.append(keypoints[22])\n",
    "        p12_y_arr.append(keypoints[23])\n",
    "        p13_x_arr.append(keypoints[24])\n",
    "        p13_y_arr.append(keypoints[25])\n",
    "        p14_x_arr.append(keypoints[26])\n",
    "        p14_y_arr.append(keypoints[27])\n",
    "        p15_x_arr.append(keypoints[28])\n",
    "        p15_y_arr.append(keypoints[29])\n",
    "        p16_x_arr.append(keypoints[30])\n",
    "        p16_y_arr.append(keypoints[31])\n",
    "        \n",
    "        j = j + 1\n",
    "        \n",
    "#         if j == 5:\n",
    "#             break\n",
    "#     break\n",
    "\n",
    "# grasp_dataset = pd.concat([pd.Series(pressure_reading_1_arr), pd.Series(pressure_reading_2_arr), pd.Series(force_reading_1_arr), pd.Series(force_reading_2_arr), pd.Series(p1_x_arr), pd.Series(p1_y_arr), pd.Series(p2_x_arr), pd.Series(p2_y_arr), pd.Series(p3_x_arr), pd.Series(p3_y_arr), pd.Series(p4_x_arr), pd.Series(p4_y_arr), pd.Series(p5_x_arr), pd.Series(p5_y_arr), pd.Series(p6_x_arr), pd.Series(p6_y_arr), pd.Series(p7_x_arr), pd.Series(p7_y_arr), pd.Series(p8_x_arr), pd.Series(p8_y_arr), pd.Series(p9_x_arr), pd.Series(p9_y_arr), pd.Series(p10_x_arr), pd.Series(p10_y_arr), pd.Series(p11_x_arr), pd.Series(p11_y_arr), pd.Series(p12_x_arr), pd.Series(p12_y_arr), pd.Series(p13_x_arr), pd.Series(p13_y_arr), pd.Series(p14_x_arr), pd.Series(p14_y_arr), pd.Series(p15_x_arr), pd.Series(p15_y_arr), pd.Series(p16_x_arr), pd.Series(p16_y_arr), pd.Series(label_arr)], axis=1, keys=header)\n",
    "grasp_dataset = pd.concat([pd.Series(pressure_reading_1_arr), pd.Series(pressure_reading_2_arr), pd.Series(p1_x_arr), pd.Series(p1_y_arr), pd.Series(p2_x_arr), pd.Series(p2_y_arr), pd.Series(p3_x_arr), pd.Series(p3_y_arr), pd.Series(p4_x_arr), pd.Series(p4_y_arr), pd.Series(p5_x_arr), pd.Series(p5_y_arr), pd.Series(p6_x_arr), pd.Series(p6_y_arr), pd.Series(p7_x_arr), pd.Series(p7_y_arr), pd.Series(p8_x_arr), pd.Series(p8_y_arr), pd.Series(p9_x_arr), pd.Series(p9_y_arr), pd.Series(p10_x_arr), pd.Series(p10_y_arr), pd.Series(p11_x_arr), pd.Series(p11_y_arr), pd.Series(p12_x_arr), pd.Series(p12_y_arr), pd.Series(p13_x_arr), pd.Series(p13_y_arr), pd.Series(p14_x_arr), pd.Series(p14_y_arr), pd.Series(p15_x_arr), pd.Series(p15_y_arr), pd.Series(p16_x_arr), pd.Series(p16_y_arr), pd.Series(label_arr)], axis=1, keys=header)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b90e6ca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   pressure_reading_1  pressure_reading_2      p1_x      p1_y      p2_x  \\\n",
      "0                11.9                16.6  0.122963  0.362666  0.468374   \n",
      "1                12.9                16.9  0.122488  0.361564  0.468206   \n",
      "\n",
      "       p2_y      p3_x      p3_y      p4_x      p4_y  ...     p12_y     p13_x  \\\n",
      "0  0.138588  0.831271  0.304085  0.842191  0.692365  ...  0.796931  0.533062   \n",
      "1  0.138091  0.830999  0.305252  0.842207  0.692010  ...  0.797243  0.532895   \n",
      "\n",
      "      p13_y     p14_x     p14_y     p15_x     p15_y     p16_x     p16_y  \\\n",
      "0  0.654710  0.538288  0.524328  0.526940  0.390195  0.507254  0.245152   \n",
      "1  0.654947  0.538029  0.524552  0.526609  0.390333  0.506905  0.245144   \n",
      "\n",
      "         label  \n",
      "0  cylinder_20  \n",
      "1  cylinder_20  \n",
      "\n",
      "[2 rows x 35 columns]\n"
     ]
    }
   ],
   "source": [
    "print(grasp_dataset.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b8afcd06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   pressure_reading_1  pressure_reading_2      p1_x      p1_y      p2_x  \\\n",
      "0                11.9                16.6  0.122963  0.362666  0.468374   \n",
      "1                12.9                16.9  0.122488  0.361564  0.468206   \n",
      "\n",
      "       p2_y      p3_x      p3_y      p4_x      p4_y  ...     p12_x     p12_y  \\\n",
      "0  0.138588  0.831271  0.304085  0.842191  0.692365  ...  0.523209  0.796931   \n",
      "1  0.138091  0.830999  0.305252  0.842207  0.692010  ...  0.523157  0.797243   \n",
      "\n",
      "      p13_x     p13_y     p14_x     p14_y     p15_x     p15_y     p16_x  \\\n",
      "0  0.533062  0.654710  0.538288  0.524328  0.526940  0.390195  0.507254   \n",
      "1  0.532895  0.654947  0.538029  0.524552  0.526609  0.390333  0.506905   \n",
      "\n",
      "      p16_y  \n",
      "0  0.245152  \n",
      "1  0.245144  \n",
      "\n",
      "[2 rows x 34 columns]\n",
      "0    cylinder_20\n",
      "1    cylinder_20\n",
      "Name: label, dtype: object\n"
     ]
    }
   ],
   "source": [
    "grasp_data = grasp_dataset.drop(columns=[\"label\"], axis=1)\n",
    "grasp_label = grasp_dataset['label']\n",
    "\n",
    "print(grasp_data.head(2))\n",
    "print(grasp_label.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d6aa8700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation results: [1.         1.         0.98333333 1.         1.         1.\n",
      " 1.         1.         1.         1.        ]\n",
      "Average accuracy: 0.9983333333333334\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(grasp_data, grasp_label, test_size=0.2, random_state=np.random.randint(100))\n",
    "\n",
    "# print(X_train.head(3))\n",
    "\n",
    "# knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# knn.fit(X_train, y_train)\n",
    "\n",
    "# y_pred = knn.predict(X_test)\n",
    "\n",
    "# accuracy = knn.score(X_test, y_test)\n",
    "# print('Accuracy:', accuracy)\n",
    "\n",
    "# clf = RandomForestClassifier(n_estimators=1000, max_depth=100, random_state=np.random.randint(100))\n",
    "# clf2 = HistGradientBoostingClassifier(max_iter=200, random_state=np.random.randint(100))\n",
    "# clf3 = GradientBoostingClassifier(n_estimators=200, learning_rate=0.1, max_depth=1, random_state=0).fit(X_train, y_train)\n",
    "# clf = VotingClassifier(estimators=[('lr', clf1), ('rf', clf2), ('gnb', clf3)],voting='hard')\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=1000, max_depth=100, random_state=np.random.randint(100), n_jobs = -1)\n",
    "num_folds = 10\n",
    "cv_method = KFold(n_splits=num_folds, shuffle=True, random_state=np.random.randint(100))\n",
    "cv_results = cross_val_score(clf, grasp_data, grasp_label, cv=cv_method, scoring='accuracy')\n",
    "\n",
    "print('Cross-validation results:', cv_results)\n",
    "print('Average accuracy:', cv_results.mean())\n",
    "\n",
    "# clf.fit(X_train, y_train)\n",
    "\n",
    "# accuracy = clf.score(X_test, y_test)\n",
    "# print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9281437",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9982fb40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f1bc14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d25dca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3427cdab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e672ddbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84543cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".Keypoint_detection_notebooks",
   "language": "python",
   "name": ".keypoint_detection_notebooks"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
