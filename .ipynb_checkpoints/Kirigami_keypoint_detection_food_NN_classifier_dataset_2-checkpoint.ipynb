{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8cbb8b46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dell/Desktop/xxxx/Uni/Kirigami_project/Keypoint_detection_notebooks/.Keypoint_detection_notebooks/lib/python3.8/site-packages/requests/__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.14) or chardet (5.1.0)/charset_normalizer (2.0.12) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "# importing relevant packages \n",
    "\n",
    "import torch \n",
    "from torchvision import models\n",
    "import pandas as pd\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "import glob\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt \n",
    "import torchvision.transforms as transforms\n",
    "from torchsummary import summary\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from PIL import Image\n",
    "import random\n",
    "import albumentations as A\n",
    "import glob\n",
    "from shapely.geometry import Polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b31d09c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_21686/2198079538.py:1: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display, HTML\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>div.output_scroll { height: 45em; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>div.output_scroll { height: 45em; }</style>\"))\n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a2a79d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VGG_model, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.LeakyReLU(0.1,inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.LeakyReLU(0.1,inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
    "            nn.Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.LeakyReLU(0.1,inplace=True),\n",
    "            nn.Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.LeakyReLU(0.1,inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
    "            nn.Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.LeakyReLU(0.1,inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.LeakyReLU(0.1,inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.LeakyReLU(0.1,inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
    "            nn.Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.LeakyReLU(0.1,inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.LeakyReLU(0.1,inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.LeakyReLU(0.1,inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
    "            nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.LeakyReLU(0.1,inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.LeakyReLU(0.1,inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "        )\n",
    "        \n",
    "        self.avgpool = nn.Sequential(\n",
    "            nn.Conv2d(512,512, kernel_size=3, padding='same'),\n",
    "            nn.LeakyReLU(0.1,inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(512,50, kernel_size=3, padding='same'),\n",
    "            nn.LeakyReLU(0.1,inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.AdaptiveAvgPool2d(output_size=(8,8))\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(3200, 300),\n",
    "            nn.LeakyReLU(0.1,inplace=True),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(300, 32),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3daa8a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = VGG_model()\n",
    "model.load_state_dict(torch.load('./Model_VGG_4_5_2000_13080_epoch'))\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d4f2ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_keypoints(img):\n",
    "    img = cv2.resize(img, (224,224))\n",
    "    img_tensor = transforms.ToTensor()(img)\n",
    "    img_mean = img_tensor.mean(dim = (1,2))\n",
    "    img_std = img_tensor.std(dim = (1,2))\n",
    "        \n",
    "    img_normalised = transforms.Normalize(img_mean, img_std)(img_tensor)\n",
    "    img_normalised = img_normalised.to(device)\n",
    "    \n",
    "    key_points = model(img_normalised[None]).flatten().detach().cpu().numpy()\n",
    "    \n",
    "    return key_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "967d6f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_keypoints(img, keypoints):                                                             \n",
    "\n",
    "    plt.imshow(img)\n",
    "\n",
    "    keypoints = np.array(keypoints)\n",
    "    \n",
    "    x_points = keypoints[0::2]\n",
    "    y_points = keypoints[1::2]\n",
    "    \n",
    "    plt.scatter(x_points*img.shape[1], y_points*img.shape[0], s = 4, c=(1,0,0))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01b342db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_num(x):\n",
    "    return x*random.uniform(0.95, 1.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5721aaf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_label(x):\n",
    "    string_to_int_dict = {'orange':0, 'pear':1, 'banana':2, 'plum':3, 'egg':4, 'strawberry':5, 'chicken':6, 'bayberry':7, 'redgrape':8, 'pistachio':9}\n",
    "    return string_to_int_dict[x]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13a18f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_image(img):\n",
    "    img = cv2.resize(img, (224,224))\n",
    "    img_tensor = transforms.ToTensor()(img)\n",
    "    img_mean = img_tensor.mean(dim = (1,2))\n",
    "    img_std = img_tensor.std(dim = (1,2))\n",
    "        \n",
    "    img_normalised = transforms.Normalize(img_mean, img_std)(img_tensor)\n",
    "    return img_normalised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "29100f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_data():\n",
    "\n",
    "    source_folder = os.path.join(os. getcwd(), 'Grasp_dataset_2')\n",
    "    destination_folder = os.path.join(os. getcwd(), 'Grasp_dataset_augmented')\n",
    "    dataset_names = ['Grasp_dataset_orange', 'Grasp_dataset_pear', 'Grasp_dataset_banana', 'Grasp_dataset_plum', 'Grasp_dataset_egg', 'Grasp_dataset_strawberry', 'Grasp_dataset_chicken', 'Grasp_dataset_bayberry', 'Grasp_dataset_redgrape', 'Grasp_dataset_pistachio']\n",
    "\n",
    "    for f in dataset_names:\n",
    "        \n",
    "        files = glob.glob(destination_folder + '/' + f + '/*')\n",
    "        \n",
    "        for file in files:\n",
    "            os.remove(file)\n",
    "        \n",
    "        df = pd.read_csv(source_folder + '/' + f + '/' + f + '.csv')\n",
    "        \n",
    "        num_cols = df.select_dtypes(include=['float']).columns\n",
    "        df[num_cols] = df[num_cols].applymap(process_num)\n",
    "        df['label'] = df['label'].apply(process_label)\n",
    "        \n",
    "#         df.to_csv(destination_folder + '/' + f + '/' + f + '.csv', index=False)\n",
    "        \n",
    "        i = 0\n",
    "        repeat = 0\n",
    "        \n",
    "        header = ['p1_x', 'p1_y', 'p2_x', 'p2_y', 'p3_x', 'p3_y', 'p4_x', 'p4_y', 'p5_x', 'p5_y', 'p6_x', 'p6_y',\n",
    "              'p7_x', 'p7_y', 'p8_x', 'p8_y', 'p9_x', 'p9_y', 'p10_x', 'p10_y', 'p11_x', 'p11_y', 'p12_x', 'p12_y', 'p13_x',\n",
    "              'p13_y', 'p14_x', 'p14_y', 'p15_x', 'p15_y', 'p16_x', 'p16_y']\n",
    "            \n",
    "        keypoints_df = pd.DataFrame(columns=header)\n",
    "        \n",
    "        while i < df.shape[0]:\n",
    "        \n",
    "            transform = A.Compose([\n",
    "                    A.Affine(rotate=random.uniform(-1, 1), p=1),\n",
    "                    A.Affine(translate_percent={'x': random.uniform(-0.02, 0.02), 'y': random.uniform(-0.02, 0.02)}, p=1),\n",
    "                    A.Affine(shear={'x': random.uniform(-1, 1), 'y': random.uniform(-0.5, 0.5)}, p=1),\n",
    "                    A.Affine(scale=(0.98, 1.01), p=1)\n",
    "                ], keypoint_params=A.KeypointParams(format='xy'))\n",
    "            \n",
    "            image_to_be_transformed = cv2.imread(os.path.join(source_folder + '/' + f, df.iloc[i]['image_name']))\n",
    "            \n",
    "            processed_image_to_be_transformed = transform_image(image_to_be_transformed)\n",
    "            processed_image_to_be_transformed = processed_image_to_be_transformed.to(device)\n",
    "\n",
    "            keypoints = model(processed_image_to_be_transformed[None]).flatten().detach().cpu().numpy()\n",
    "            \n",
    "            x_points = keypoints[0::2]\n",
    "            y_points = keypoints[1::2]\n",
    "            x_points = x_points*image_to_be_transformed.shape[1]\n",
    "            y_points = y_points*image_to_be_transformed.shape[0]\n",
    "\n",
    "            transformed = transform(image=image_to_be_transformed, keypoints=list(zip(x_points, y_points)))\n",
    "            transformed_image = transformed['image']\n",
    "            transformed_keypoints = transformed['keypoints']\n",
    "            \n",
    "            if repeat >= 20:\n",
    "                print('skipping')\n",
    "                repeat = 0\n",
    "                i = i + 1\n",
    "                continue\n",
    "    \n",
    "            if len(transformed_keypoints) != 16:\n",
    "#                 print(df.iloc[i]['image_name'])\n",
    "                repeat = repeat + 1\n",
    "                continue\n",
    "            \n",
    "            flatten_coordinates = np.array(transformed_keypoints).flatten()\n",
    "            flatten_coordinates[::2] = [x / transformed_image.shape[1] for x in flatten_coordinates[::2]]\n",
    "            flatten_coordinates[1::2] = [x / transformed_image.shape[0] for x in flatten_coordinates[1::2]]\n",
    "            keypoints_df.loc[len(keypoints_df)] = pd.Series(flatten_coordinates, index=header)\n",
    "#             print(flatten_coordinates)\n",
    "#             print(keypoints_df)\n",
    "            \n",
    "            transformed_image[..., [0, 2]] = transformed_image[..., [2, 0]]\n",
    "            img = Image.fromarray(np.uint8(transformed_image))\n",
    "            img.save(destination_folder + '/' + f + '/' + df.iloc[i]['image_name'])\n",
    "            \n",
    "#             plot_keypoints(transformed_image, flatten_coordinates)\n",
    "            \n",
    "            repeat = 0\n",
    "            i = i + 1\n",
    "        \n",
    "        complete_df = pd.concat([df, keypoints_df], axis=1)\n",
    "        complete_df.to_csv(destination_folder + '/' + f + '/' + f + '.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94758946",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_image = cv2.imread('/home/dell/Desktop/xxxx/Uni/Kirigami_project/Keypoint_detection_notebooks/Grasp_dataset_augmented/Grasp_dataset_orange/Gimage10.jpg')\n",
    "# test_keypoints = [0.12771776,0.2779994,0.47523814,0.025530297,0.8148705,0.2775899,0.8246956,0.62812585,0.49508992,0.9256545,0.15821105,0.73071223,0.43649036,0.20082472,0.40966305,0.36028758,0.39995593,0.49125895,0.41422606,0.61616457,0.44915825,0.75999326,0.52863693,0.7681227,0.5525919,0.6140371,0.5610489,0.49106207,0.5443897,0.3638414,0.51417565,0.20984803]\n",
    "# print(len(test_keypoints))\n",
    "# plot_keypoints(test_image, test_keypoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "337c9168",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_datasets():\n",
    "\n",
    "    destination_folder = os.path.join(os. getcwd(), 'Grasp_dataset_augmented')\n",
    "    dataset_names = ['Grasp_dataset_orange', 'Grasp_dataset_pear', 'Grasp_dataset_banana', 'Grasp_dataset_plum', 'Grasp_dataset_egg', 'Grasp_dataset_strawberry', 'Grasp_dataset_chicken', 'Grasp_dataset_bayberry', 'Grasp_dataset_redgrape', 'Grasp_dataset_pistachio']\n",
    "\n",
    "    complete_df_set = pd.DataFrame()\n",
    "    first_dataset = True\n",
    "\n",
    "    for f in dataset_names:\n",
    "\n",
    "        df = pd.read_csv(destination_folder + '/' + f + '/' + f + '.csv')\n",
    "\n",
    "        if first_dataset == True:\n",
    "            complete_df_set = df\n",
    "            first_dataset = False\n",
    "        else:\n",
    "            complete_df_set = pd.concat([complete_df_set, df], axis=0)\n",
    "\n",
    "    complete_df_set.to_csv(destination_folder + '/' + 'Grasp_dataset_augmented.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7fd9989",
   "metadata": {},
   "outputs": [],
   "source": [
    "augment_data()\n",
    "combine_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6aa8700",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# augment_data()\n",
    "# combine_datasets()\n",
    "\n",
    "# grasp_dataset = pd.read_csv(os. getcwd() + '/' + 'Grasp_dataset_augmented/Grasp_dataset_augmented.csv')\n",
    "\n",
    "# print(grasp_dataset.tail(2))\n",
    "\n",
    "\n",
    "# data_train, data_test, label_train, label_test = train_test_split(grasp_data, grasp_label, test_size=0.2, random_state=np.random.randint(100))\n",
    "\n",
    "# clf = RandomForestClassifier(n_estimators=100, max_depth=100, random_state=np.random.randint(100))\n",
    "\n",
    "# num_folds = 10\n",
    "# cv_method = KFold(n_splits=num_folds, shuffle=True, random_state=np.random.randint(100))\n",
    "# cv_results = cross_val_score(clf, grasp_data, grasp_label, cv=cv_method, scoring='accuracy')\n",
    "\n",
    "# print('Cross-validation results:', cv_results)\n",
    "# print('Average accuracy:', cv_results.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "859ae9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassifierDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        self.data, self.label = self.clean_data(df) # clean data\n",
    "        \n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        data = self.data.iloc[idx]\n",
    "        label = self.label.iloc[idx]\n",
    "#         label = F.one_hot(torch.tensor(label), 10)\n",
    "        \n",
    "        return torch.tensor(data, dtype=torch.float32).to(device), torch.tensor(label, dtype=torch.int64).to(device)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "\n",
    "    \n",
    "    def clean_data(self, grasp_dataset):\n",
    "        grasp_data = grasp_dataset.drop(columns=['image_name', 'label'], axis=1)\n",
    "        grasp_data['pressure_reading_1'] = grasp_data['pressure_reading_1'] / 100\n",
    "        grasp_data['pressure_reading_2'] = grasp_data['pressure_reading_2'] / 100\n",
    "        grasp_data['force_reading_1'] = grasp_data['force_reading_1'] / 1000\n",
    "        grasp_data['force_reading_2'] = grasp_data['force_reading_2'] / 1000\n",
    "        grasp_label = grasp_dataset['label']\n",
    "\n",
    "        return grasp_data, grasp_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5841e795",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grasp_dataset = pd.read_csv(os. getcwd() + '/' + 'Grasp_dataset_augmented/Grasp_dataset_augmented.csv')\n",
    "\n",
    "# train_df, test_df = train_test_split(grasp_dataset, test_size=0.1)\n",
    "\n",
    "# train_dataset = ClassifierDataset(train_df)\n",
    "# test_dataset = ClassifierDataset(test_df)\n",
    "\n",
    "# train_dataloader = DataLoader(train_dataset, batch_size=2, shuffle=True)\n",
    "# test_dataloader = DataLoader(test_dataset, batch_size=2, shuffle=True)\n",
    "\n",
    "# for data in train_dataloader:\n",
    "#     break\n",
    "\n",
    "# input_data, target_output = data\n",
    "# print(input_data)\n",
    "# print(target_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9982fb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(16*2+4, 64),\n",
    "            nn.LeakyReLU(0.1,inplace=True),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.LeakyReLU(0.1,inplace=True),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.LeakyReLU(0.1,inplace=True),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(32, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "31f1bc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_model = MLP()\n",
    "classification_model = classification_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e7d25dca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                [-1, 8, 64]           2,368\n",
      "         LeakyReLU-2                [-1, 8, 64]               0\n",
      "           Dropout-3                [-1, 8, 64]               0\n",
      "            Linear-4                [-1, 8, 64]           4,160\n",
      "         LeakyReLU-5                [-1, 8, 64]               0\n",
      "           Dropout-6                [-1, 8, 64]               0\n",
      "            Linear-7                [-1, 8, 32]           2,080\n",
      "         LeakyReLU-8                [-1, 8, 32]               0\n",
      "           Dropout-9                [-1, 8, 32]               0\n",
      "           Linear-10                [-1, 8, 10]             330\n",
      "================================================================\n",
      "Total params: 8,938\n",
      "Trainable params: 8,938\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.03\n",
      "Params size (MB): 0.03\n",
      "Estimated Total Size (MB): 0.07\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(classification_model, (8,16*2+4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cd4d3b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_training_set():\n",
    "\n",
    "    global train_df, test_df, train_dataset, test_dataset, train_dataloader, test_dataloader, image_data\n",
    "    \n",
    "    destination_folder = os.path.join(os. getcwd(), 'Grasp_dataset_augmented')\n",
    "\n",
    "    augment_data()\n",
    "    combine_datasets()\n",
    "    \n",
    "    grasp_dataset = pd.read_csv(os. getcwd() + '/' + 'Grasp_dataset_augmented/Grasp_dataset_augmented.csv')\n",
    "    \n",
    "    train_df, test_df = train_test_split(grasp_dataset, test_size=0.1)\n",
    "    \n",
    "    train_dataset = ClassifierDataset(train_df)\n",
    "    test_dataset = ClassifierDataset(test_df)\n",
    "    \n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=2, shuffle=True)\n",
    "    \n",
    "    print('Finished.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4bfd2f0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished.\n"
     ]
    }
   ],
   "source": [
    "update_training_set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3427cdab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_essentials():\n",
    "    loss_fun = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(classification_model.parameters(), lr=0.00001)\n",
    "    return loss_fun, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e672ddbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_batch(data, model, loss_fun, optimizer):\n",
    "    model.train()\n",
    "    input_data, target_output = data\n",
    "    pred_output = model(input_data)\n",
    "    loss = loss_fun(pred_output, target_output)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    return loss.item()\n",
    "\n",
    "@torch.no_grad()\n",
    "def val_batch(data, model, loss_fun, optimizer):\n",
    "    model.eval()\n",
    "    input_data, target_output = data\n",
    "    pred_output = model(input_data.to(torch.float32))\n",
    "    loss = loss_fun(pred_output, target_output)\n",
    "    return loss.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b84543cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1000\n",
    "loss_fun, optimizer = get_essentials()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3d274e7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                  | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.244328498840332 2.3120760917663574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                        | 2/1000 [00:10<1:14:39,  4.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▎                                         | 7/1000 [00:11<08:41,  1.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2434916496276855 2.332185745239258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▍                                        | 12/1000 [00:12<02:52,  5.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.315312385559082 2.3312060832977295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▋                                        | 17/1000 [00:12<01:58,  8.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.250145673751831 2.304664134979248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▉                                        | 22/1000 [00:13<01:49,  8.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3017425537109375 2.259577751159668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|█                                        | 27/1000 [00:13<01:46,  9.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4128427505493164 2.222106695175171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|█▎                                       | 32/1000 [00:14<01:45,  9.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3031258583068848 2.337130546569824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|█▌                                       | 37/1000 [00:14<01:45,  9.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3232221603393555 2.1844377517700195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|█▋                                       | 42/1000 [00:15<01:44,  9.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2716338634490967 2.3141040802001953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|█▉                                       | 47/1000 [00:15<01:44,  9.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3683109283447266 2.300570011138916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|██▏                                      | 52/1000 [00:16<01:43,  9.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4387335777282715 2.32846736907959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|██▎                                      | 57/1000 [00:16<01:43,  9.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2909603118896484 2.39018177986145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|██▌                                      | 62/1000 [00:17<01:42,  9.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.307255983352661 2.327665328979492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|██▋                                      | 67/1000 [00:18<01:42,  9.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.345355987548828 2.3871469497680664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|██▉                                      | 72/1000 [00:18<01:41,  9.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.29530668258667 2.326395034790039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|███▏                                     | 77/1000 [00:19<01:45,  8.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3236632347106934 2.228661060333252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|███▎                                     | 82/1000 [00:19<01:43,  8.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.354004383087158 2.2966389656066895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|███▌                                     | 87/1000 [00:20<01:44,  8.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3021507263183594 2.3542046546936035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|███▊                                     | 92/1000 [00:20<01:42,  8.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2613887786865234 2.3840785026550293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|███▉                                     | 97/1000 [00:21<01:41,  8.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.27256441116333 2.305790662765503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████                                    | 100/1000 [00:21<01:39,  9.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3040542602539062 2.3043251037597656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████                                    | 102/1000 [00:33<36:55,  2.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|████▎                                   | 107/1000 [00:33<07:34,  1.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.307950735092163 2.311115264892578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|████▍                                   | 112/1000 [00:34<02:44,  5.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.371237277984619 2.390427827835083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|████▋                                   | 117/1000 [00:35<02:02,  7.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3486008644104004 2.309810161590576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|████▉                                   | 122/1000 [00:35<01:47,  8.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4101011753082275 2.313748836517334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█████                                   | 127/1000 [00:36<01:40,  8.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.317300319671631 2.287165641784668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█████▎                                  | 132/1000 [00:36<01:36,  8.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3397140502929688 2.228121757507324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█████▍                                  | 137/1000 [00:37<01:38,  8.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.328808307647705 2.3163928985595703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█████▋                                  | 142/1000 [00:37<01:44,  8.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.314906358718872 2.3397574424743652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█████▉                                  | 147/1000 [00:38<01:40,  8.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3108930587768555 2.349055767059326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|██████                                  | 152/1000 [00:39<01:38,  8.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3893918991088867 2.309941291809082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|██████▎                                 | 157/1000 [00:39<01:38,  8.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3357603549957275 2.313739061355591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|██████▍                                 | 162/1000 [00:40<01:37,  8.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2691287994384766 2.3046529293060303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|██████▋                                 | 167/1000 [00:40<01:37,  8.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2323083877563477 2.296764373779297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|██████▉                                 | 172/1000 [00:41<01:35,  8.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.41864013671875 2.2951879501342773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|███████                                 | 177/1000 [00:42<01:36,  8.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3527371883392334 2.365959405899048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|███████▎                                | 182/1000 [00:42<01:36,  8.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3456244468688965 2.28037691116333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|███████▍                                | 187/1000 [00:43<01:34,  8.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.262589931488037 2.3341622352600098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|███████▋                                | 192/1000 [00:43<01:35,  8.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.332143783569336 2.2727880477905273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|███████▉                                | 197/1000 [00:44<01:33,  8.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3049731254577637 2.299670457839966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████                                | 200/1000 [00:44<01:31,  8.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1978206634521484 2.333038330078125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████                                | 202/1000 [00:56<33:53,  2.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|████████▎                               | 207/1000 [00:57<06:54,  1.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3987374305725098 2.3331103324890137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|████████▍                               | 212/1000 [00:57<02:24,  5.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.274350881576538 2.274167060852051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|████████▋                               | 217/1000 [00:58<01:37,  8.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.227907657623291 2.2847933769226074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|████████▉                               | 222/1000 [00:58<01:31,  8.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.249382972717285 2.2192111015319824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|█████████                               | 227/1000 [00:59<01:29,  8.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.361584424972534 2.338831901550293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|█████████▎                              | 232/1000 [00:59<01:28,  8.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.251065492630005 2.274947166442871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|█████████▍                              | 237/1000 [01:00<01:29,  8.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2722396850585938 2.3022494316101074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|█████████▋                              | 242/1000 [01:01<01:29,  8.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.29256534576416 2.2576711177825928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|█████████▉                              | 247/1000 [01:01<01:29,  8.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2124385833740234 2.296048164367676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██████████                              | 252/1000 [01:02<01:24,  8.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3468246459960938 2.2925524711608887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██████████▎                             | 257/1000 [01:02<01:22,  9.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2527616024017334 2.3514459133148193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██████████▍                             | 262/1000 [01:03<01:20,  9.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2476720809936523 2.3057498931884766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██████████▋                             | 267/1000 [01:03<01:20,  9.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.340217113494873 2.249368190765381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██████████▉                             | 272/1000 [01:04<01:20,  9.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.315337657928467 2.307103157043457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|███████████                             | 277/1000 [01:05<01:19,  9.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.177008628845215 2.300293445587158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|███████████▎                            | 282/1000 [01:05<01:17,  9.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3117871284484863 2.2003774642944336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|███████████▍                            | 287/1000 [01:06<01:17,  9.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2471022605895996 2.2903645038604736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|███████████▋                            | 292/1000 [01:06<01:15,  9.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2242958545684814 2.148601531982422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███████████▉                            | 297/1000 [01:07<01:15,  9.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.343099355697632 2.2884464263916016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████                            | 300/1000 [01:07<01:16,  9.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.231257915496826 2.282179594039917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████                            | 300/1000 [01:18<03:03,  3.82it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 18\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (epoch) \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     17\u001b[0m     torch\u001b[38;5;241m.\u001b[39msave(classification_model\u001b[38;5;241m.\u001b[39mstate_dict(), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./Temp_models/Model_classify_dataset_2\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(epoch) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_epoch\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 18\u001b[0m     \u001b[43mupdate_training_set\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[18], line 7\u001b[0m, in \u001b[0;36mupdate_training_set\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m train_df, test_df, train_dataset, test_dataset, train_dataloader, test_dataloader, image_data\n\u001b[1;32m      5\u001b[0m destination_folder \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(os\u001b[38;5;241m.\u001b[39m getcwd(), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGrasp_dataset_augmented\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m \u001b[43maugment_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m combine_datasets()\n\u001b[1;32m     10\u001b[0m grasp_dataset \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(os\u001b[38;5;241m.\u001b[39m getcwd() \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGrasp_dataset_augmented/Grasp_dataset_augmented.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[12], line 45\u001b[0m, in \u001b[0;36maugment_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m processed_image_to_be_transformed \u001b[38;5;241m=\u001b[39m transform_image(image_to_be_transformed)\n\u001b[1;32m     43\u001b[0m processed_image_to_be_transformed \u001b[38;5;241m=\u001b[39m processed_image_to_be_transformed\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 45\u001b[0m keypoints \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocessed_image_to_be_transformed\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m     47\u001b[0m x_points \u001b[38;5;241m=\u001b[39m keypoints[\u001b[38;5;241m0\u001b[39m::\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m     48\u001b[0m y_points \u001b[38;5;241m=\u001b[39m keypoints[\u001b[38;5;241m1\u001b[39m::\u001b[38;5;241m2\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_epoch, val_epoch = [], []\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    train_batch_losses, val_batch_losses = [], []\n",
    "    for data in train_dataloader:\n",
    "        train_batch_loss = train_batch(data, classification_model, loss_fun, optimizer)\n",
    "        train_batch_losses.append(train_batch_loss)\n",
    "    for data in test_dataloader:\n",
    "        val_batch_loss = val_batch(data, classification_model, loss_fun, optimizer)\n",
    "        val_batch_losses.append(val_batch_loss)\n",
    "    train_epoch.append(np.mean(train_batch_losses))\n",
    "    val_epoch.append(np.mean(val_batch_losses))\n",
    "\n",
    "    if epoch % 5 == 0:\n",
    "        print(train_batch_loss, val_batch_loss)\n",
    "    \n",
    "    if (epoch) % 100 == 0:\n",
    "        torch.save(classification_model.state_dict(), './Temp_models/Model_classify_dataset_2' + str(epoch) + '_epoch')\n",
    "        update_training_set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0cb9eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(epochs), train_epoch, label=\"train_loss\")\n",
    "plt.plot(range(epochs), val_epoch, label=\"test_loss\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training Facial Keypoints model\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbac6940",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "Grasp_dataset_validation = pd.read_csv(os. getcwd() + '/' + 'Grasp_dataset_validation/Grasp_dataset_validation.csv')\n",
    "    \n",
    "\n",
    "validation_dataset = ClassifierDataset(Grasp_dataset_validation)\n",
    "    \n",
    "validation_dataloader = DataLoader(validation_dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "with torch.no_grad():\n",
    "    classification_model.eval()\n",
    "    for data in validation_dataloader:\n",
    "        input_data, labels = data\n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = classification_model(input_data)\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on the 100 test images: {100 * correct // total} %')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5530acc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e235c848",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".Keypoint_detection_notebooks",
   "language": "python",
   "name": ".keypoint_detection_notebooks"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
