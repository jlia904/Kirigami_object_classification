{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8cbb8b46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dell/Desktop/xxxx/Uni/Kirigami_project/Keypoint_detection_notebooks/.Keypoint_detection_notebooks/lib/python3.8/site-packages/requests/__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.14) or chardet (5.1.0)/charset_normalizer (2.0.12) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "# importing relevant packages \n",
    "\n",
    "import torch \n",
    "from torchvision import models\n",
    "import pandas as pd\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn \n",
    "import glob\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt \n",
    "from matplotlib import pyplot\n",
    "import torchvision.transforms as transforms\n",
    "from torchsummary import summary\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from PIL import Image\n",
    "import random\n",
    "import albumentations as A\n",
    "import glob\n",
    "from shapely.geometry import Polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a2a79d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VGG_model, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.LeakyReLU(0.1,inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.LeakyReLU(0.1,inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
    "            nn.Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.LeakyReLU(0.1,inplace=True),\n",
    "            nn.Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.LeakyReLU(0.1,inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
    "            nn.Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.LeakyReLU(0.1,inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.LeakyReLU(0.1,inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.LeakyReLU(0.1,inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
    "            nn.Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.LeakyReLU(0.1,inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.LeakyReLU(0.1,inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.LeakyReLU(0.1,inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
    "            nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.LeakyReLU(0.1,inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.LeakyReLU(0.1,inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "        )\n",
    "        \n",
    "        self.avgpool = nn.Sequential(\n",
    "            nn.Conv2d(512,512, kernel_size=3, padding='same'),\n",
    "            nn.LeakyReLU(0.1,inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(512,50, kernel_size=3, padding='same'),\n",
    "            nn.LeakyReLU(0.1,inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.AdaptiveAvgPool2d(output_size=(8,8))\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(3200, 300),\n",
    "            nn.LeakyReLU(0.1,inplace=True),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(300, 32),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3daa8a88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG_model(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): Sequential(\n",
       "    (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "    (1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(512, 50, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "    (4): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): AdaptiveAvgPool2d(output_size=(8, 8))\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=3200, out_features=300, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    (2): Dropout(p=0.3, inplace=False)\n",
       "    (3): Linear(in_features=300, out_features=32, bias=True)\n",
       "    (4): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = VGG_model()\n",
    "model.load_state_dict(torch.load('./Model_VGG_4_5_6_2000_16300_epoch'))\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d4f2ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_keypoints(img):\n",
    "    img = cv2.resize(img, (224,224))\n",
    "    img_tensor = transforms.ToTensor()(img)\n",
    "    img_mean = img_tensor.mean(dim = (1,2))\n",
    "    img_std = img_tensor.std(dim = (1,2))\n",
    "        \n",
    "    img_normalised = transforms.Normalize(img_mean, img_std)(img_tensor)\n",
    "    img_normalised = img_normalised.to(device)\n",
    "    \n",
    "    key_points = model(img_normalised[None]).flatten().detach().cpu().numpy()\n",
    "    \n",
    "    return key_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "967d6f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_keypoints(img, keypoints):                                                             \n",
    "\n",
    "    plt.imshow(img)\n",
    "\n",
    "    x_points = keypoints[0::2]\n",
    "    y_points = keypoints[1::2]\n",
    "    plt.scatter(x_points*img.shape[1], y_points*img.shape[0], s = 4, c=(1,0,0))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3eadde89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_num(x):\n",
    "    return x*random.uniform(0.96, 1.04)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "337c9168",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_names = ['Grasp_dataset_chicken', 'Grasp_dataset_egg', 'Grasp_dataset_tomato']\n",
    "dataset_names = ['Grasp_dataset_test']\n",
    "header = ['weight_reading_1', 'weight_reading_2', 'pressure_reading_1', 'pressure_reading_2', 'force_reading_1', 'force_reading_2', 'p1_x', 'p1_y', 'p2_x', 'p2_y', 'p3_x', 'p3_y', 'p4_x', 'p4_y', 'p5_x', 'p5_y', 'p6_x', 'p6_y', 'p7_x', 'p7_y', 'p8_x', 'p8_y', 'p9_x', 'p9_y', 'p10_x', 'p10_y', 'p11_x', 'p11_y', 'p12_x', 'p12_y', 'p13_x', 'p13_y', 'p14_x', 'p14_y', 'p15_x', 'p15_y', 'p16_x', 'p16_y', 'label']\n",
    "\n",
    "current_dir = os. getcwd()\n",
    "\n",
    "weight_reading_1_arr = []\n",
    "weight_reading_2_arr = []\n",
    "pressure_reading_1_arr = []\n",
    "pressure_reading_2_arr = []\n",
    "force_reading_1_arr = []\n",
    "force_reading_2_arr = []\n",
    "\n",
    "p1_x_arr = []\n",
    "p1_y_arr = []\n",
    "p2_x_arr = []\n",
    "p2_y_arr = []\n",
    "p3_x_arr = []\n",
    "p3_y_arr = []\n",
    "p4_x_arr = []\n",
    "p4_y_arr = []\n",
    "p5_x_arr = []\n",
    "p5_y_arr = []\n",
    "p6_x_arr = []\n",
    "p6_y_arr = []\n",
    "p7_x_arr = []\n",
    "p7_y_arr = []\n",
    "p8_x_arr = []\n",
    "p8_y_arr = []\n",
    "p9_x_arr = []\n",
    "p9_y_arr = []\n",
    "p10_x_arr = []\n",
    "p10_y_arr = []\n",
    "p11_x_arr = []\n",
    "p11_y_arr = []\n",
    "p12_x_arr = []\n",
    "p12_y_arr = []\n",
    "p13_x_arr = []\n",
    "p13_y_arr = []\n",
    "p14_x_arr = []\n",
    "p14_y_arr = []\n",
    "p15_x_arr = []\n",
    "p15_y_arr = []\n",
    "p16_x_arr = []\n",
    "p16_y_arr = []\n",
    "label_arr = []\n",
    "\n",
    "\n",
    "for f in dataset_names:\n",
    "    \n",
    "    image_dir = os.path.join(current_dir + '/Grasp_dataset_4', f)\n",
    "    data_dir = os.path.join(image_dir, f + '.csv')\n",
    "    df = pd.read_csv(data_dir)\n",
    "    weight_reading_1_arr = np.concatenate((weight_reading_1_arr, df['weight_reading_1'].values))\n",
    "    weight_reading_2_arr = np.concatenate((weight_reading_2_arr, df['weight_reading_2'].values))\n",
    "    pressure_reading_1_arr = np.concatenate((pressure_reading_1_arr, df['pressure_reading_1'].values))\n",
    "    pressure_reading_2_arr = np.concatenate((pressure_reading_2_arr, df['pressure_reading_2'].values))\n",
    "    force_reading_1_arr = np.concatenate((force_reading_1_arr, df['force_reading_1'].values))\n",
    "    force_reading_2_arr = np.concatenate((force_reading_2_arr, df['force_reading_2'].values))\n",
    "    label_arr = np.concatenate((label_arr, df['label'].values))\n",
    "    \n",
    "    j = 0\n",
    "    \n",
    "    while j < df.shape[0]:\n",
    "        image = cv2.imread(os.path.join(image_dir, df.iloc[j]['image_name']))\n",
    "        keypoints = predict_keypoints(image)\n",
    "        \n",
    "#         plot_keypoints(image, keypoints)\n",
    "        \n",
    "#         if j == 20:\n",
    "#             plot_keypoints(image, keypoints)\n",
    "        \n",
    "\n",
    "#         plt.imshow(image)\n",
    "\n",
    "#         plt.scatter(kirigami_x_points*image.shape[1], kirigami_y_points*image.shape[0], s = 4, c=(1,0,0))\n",
    "#         plt.show()\n",
    "        \n",
    "        p1_x_arr.append(keypoints[0])\n",
    "        p1_y_arr.append(keypoints[1])\n",
    "        p2_x_arr.append(keypoints[2])\n",
    "        p2_y_arr.append(keypoints[3])\n",
    "        p3_x_arr.append(keypoints[4])\n",
    "        p3_y_arr.append(keypoints[5])\n",
    "        p4_x_arr.append(keypoints[6])\n",
    "        p4_y_arr.append(keypoints[7])\n",
    "        p5_x_arr.append(keypoints[8])\n",
    "        p5_y_arr.append(keypoints[9])\n",
    "        p6_x_arr.append(keypoints[10])\n",
    "        p6_y_arr.append(keypoints[11])\n",
    "        p7_x_arr.append(keypoints[12])\n",
    "        p7_y_arr.append(keypoints[13])\n",
    "        p8_x_arr.append(keypoints[14])\n",
    "        p8_y_arr.append(keypoints[15])\n",
    "        p9_x_arr.append(keypoints[16])\n",
    "        p9_y_arr.append(keypoints[17])\n",
    "        p10_x_arr.append(keypoints[18])\n",
    "        p10_y_arr.append(keypoints[19])\n",
    "        p11_x_arr.append(keypoints[20])\n",
    "        p11_y_arr.append(keypoints[21])\n",
    "        p12_x_arr.append(keypoints[22])\n",
    "        p12_y_arr.append(keypoints[23])\n",
    "        p13_x_arr.append(keypoints[24])\n",
    "        p13_y_arr.append(keypoints[25])\n",
    "        p14_x_arr.append(keypoints[26])\n",
    "        p14_y_arr.append(keypoints[27])\n",
    "        p15_x_arr.append(keypoints[28])\n",
    "        p15_y_arr.append(keypoints[29])\n",
    "        p16_x_arr.append(keypoints[30])\n",
    "        p16_y_arr.append(keypoints[31])\n",
    "        \n",
    "        j = j + 1\n",
    "        \n",
    "#         if j == 2:\n",
    "#             break\n",
    "#     break\n",
    "\n",
    "\n",
    "\n",
    "p1_x_arr = np.array(p1_x_arr) - np.array(p1_x_arr)\n",
    "p2_x_arr = np.array(p2_x_arr) - np.array(p1_x_arr)\n",
    "p3_x_arr = np.array(p3_x_arr) - np.array(p1_x_arr)\n",
    "p4_x_arr = np.array(p4_x_arr) - np.array(p1_x_arr)\n",
    "p5_x_arr = np.array(p5_x_arr) - np.array(p1_x_arr)\n",
    "p6_x_arr = np.array(p6_x_arr) - np.array(p1_x_arr)\n",
    "p7_x_arr = np.array(p7_x_arr) - np.array(p1_x_arr)\n",
    "p8_x_arr = np.array(p8_x_arr) - np.array(p1_x_arr)\n",
    "p9_x_arr = np.array(p9_x_arr) - np.array(p1_x_arr)\n",
    "p10_x_arr = np.array(p10_x_arr) - np.array(p1_x_arr)\n",
    "p11_x_arr = np.array(p11_x_arr) - np.array(p1_x_arr)\n",
    "p12_x_arr = np.array(p12_x_arr) - np.array(p1_x_arr)\n",
    "p13_x_arr = np.array(p13_x_arr) - np.array(p1_x_arr)\n",
    "p14_x_arr = np.array(p14_x_arr) - np.array(p1_x_arr)\n",
    "p15_x_arr = np.array(p15_x_arr) - np.array(p1_x_arr)\n",
    "p16_x_arr = np.array(p16_x_arr) - np.array(p1_x_arr)\n",
    "\n",
    "p1_y_arr = np.array(p1_y_arr) - np.array(p1_y_arr)\n",
    "p2_y_arr = np.array(p2_y_arr) - np.array(p1_y_arr)\n",
    "p3_y_arr = np.array(p3_y_arr) - np.array(p1_y_arr)\n",
    "p4_y_arr = np.array(p4_y_arr) - np.array(p1_y_arr)\n",
    "p5_y_arr = np.array(p5_y_arr) - np.array(p1_y_arr)\n",
    "p6_y_arr = np.array(p6_y_arr) - np.array(p1_y_arr)\n",
    "p7_y_arr = np.array(p7_y_arr) - np.array(p1_y_arr)\n",
    "p8_y_arr = np.array(p8_y_arr) - np.array(p1_y_arr)\n",
    "p9_y_arr = np.array(p9_y_arr) - np.array(p1_y_arr)\n",
    "p10_y_arr = np.array(p10_y_arr) - np.array(p1_y_arr)\n",
    "p11_y_arr = np.array(p11_y_arr) - np.array(p1_y_arr)\n",
    "p12_y_arr = np.array(p12_y_arr) - np.array(p1_y_arr)\n",
    "p13_y_arr = np.array(p13_y_arr) - np.array(p1_y_arr)\n",
    "p14_y_arr = np.array(p14_y_arr) - np.array(p1_y_arr)\n",
    "p15_y_arr = np.array(p15_y_arr) - np.array(p1_y_arr)\n",
    "p16_y_arr = np.array(p16_y_arr) - np.array(p1_y_arr)\n",
    "\n",
    "\n",
    "weight_diff_1_arr = np.array(weight_reading_1_arr) - np.array(force_reading_1_arr)\n",
    "weight_diff_2_arr = np.array(force_reading_2_arr) - np.array(weight_reading_2_arr) \n",
    "\n",
    "grasp_dataset = pd.concat([pd.Series(weight_diff_1_arr), pd.Series(weight_diff_2_arr), pd.Series(pressure_reading_1_arr), pd.Series(pressure_reading_2_arr), pd.Series(force_reading_1_arr), pd.Series(force_reading_2_arr), pd.Series(p1_x_arr), pd.Series(p1_y_arr), pd.Series(p2_x_arr), pd.Series(p2_y_arr), pd.Series(p3_x_arr), pd.Series(p3_y_arr), pd.Series(p4_x_arr), pd.Series(p4_y_arr), pd.Series(p5_x_arr), pd.Series(p5_y_arr), pd.Series(p6_x_arr), pd.Series(p6_y_arr), pd.Series(p7_x_arr), pd.Series(p7_y_arr), pd.Series(p8_x_arr), pd.Series(p8_y_arr), pd.Series(p9_x_arr), pd.Series(p9_y_arr), pd.Series(p10_x_arr), pd.Series(p10_y_arr), pd.Series(p11_x_arr), pd.Series(p11_y_arr), pd.Series(p12_x_arr), pd.Series(p12_y_arr), pd.Series(p13_x_arr), pd.Series(p13_y_arr), pd.Series(p14_x_arr), pd.Series(p14_y_arr), pd.Series(p15_x_arr), pd.Series(p15_y_arr), pd.Series(p16_x_arr), pd.Series(p16_y_arr), pd.Series(label_arr)], axis=1, keys=header)\n",
    "\n",
    "# num_cols = grasp_dataset.select_dtypes(include=['float']).columns\n",
    "# df[num_cols] = grasp_dataset[num_cols].applymap(process_num)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b90e6ca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   weight_reading_1  weight_reading_2  pressure_reading_1  pressure_reading_2  \\\n",
      "0              83.2              83.2                66.6                57.1   \n",
      "1              77.8              87.9                62.0                66.0   \n",
      "2              89.2              76.7                34.9                50.4   \n",
      "\n",
      "   force_reading_1  force_reading_2  p1_x  p1_y      p2_x      p2_y      p3_x  \\\n",
      "0            250.6            252.2   0.0   0.0  0.486772  0.122603  0.824980   \n",
      "1            268.7            269.3   0.0   0.0  0.482807  0.125205  0.810595   \n",
      "2            289.2            290.0   0.0   0.0  0.487183  0.126480  0.823707   \n",
      "\n",
      "       p3_y      p4_x      p4_y      p5_x      p5_y      p6_x      p6_y  \\\n",
      "0  0.335509  0.832723  0.685898  0.496715  0.950725  0.165411  0.694735   \n",
      "1  0.342980  0.817371  0.672976  0.493479  0.947772  0.158876  0.719923   \n",
      "2  0.333231  0.830686  0.684766  0.495617  0.947357  0.165857  0.699332   \n",
      "\n",
      "       p7_x      p7_y      p8_x      p8_y      p9_x      p9_y     p10_x  \\\n",
      "0  0.467072  0.247196  0.457011  0.396566  0.450612  0.526023  0.459656   \n",
      "1  0.460517  0.248830  0.448322  0.398315  0.441560  0.527047  0.451084   \n",
      "2  0.468062  0.248469  0.458380  0.397180  0.451829  0.526704  0.460272   \n",
      "\n",
      "      p10_y     p11_x     p11_y     p12_x     p12_y     p13_x     p13_y  \\\n",
      "0  0.655509  0.475720  0.802080  0.520294  0.814611  0.532672  0.663148   \n",
      "1  0.655789  0.469036  0.801835  0.511638  0.815946  0.520894  0.664182   \n",
      "2  0.656193  0.475453  0.802077  0.519133  0.814081  0.531606  0.662869   \n",
      "\n",
      "      p14_x     p14_y     p15_x     p15_y     p16_x     p16_y    label  \n",
      "0  0.538515  0.535099  0.528032  0.406524  0.510347  0.261392  chicken  \n",
      "1  0.526259  0.534747  0.516774  0.405286  0.501774  0.260312  chicken  \n",
      "2  0.537763  0.534894  0.527670  0.406628  0.510563  0.262032  chicken  \n"
     ]
    }
   ],
   "source": [
    "pd.options.display.max_columns = None\n",
    "print(grasp_dataset.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6b621963",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weight_reading_1</th>\n",
       "      <th>weight_reading_2</th>\n",
       "      <th>pressure_reading_1</th>\n",
       "      <th>pressure_reading_2</th>\n",
       "      <th>force_reading_1</th>\n",
       "      <th>force_reading_2</th>\n",
       "      <th>p1_x</th>\n",
       "      <th>p1_y</th>\n",
       "      <th>p2_x</th>\n",
       "      <th>p2_y</th>\n",
       "      <th>p3_x</th>\n",
       "      <th>p3_y</th>\n",
       "      <th>p4_x</th>\n",
       "      <th>p4_y</th>\n",
       "      <th>p5_x</th>\n",
       "      <th>p5_y</th>\n",
       "      <th>p6_x</th>\n",
       "      <th>p6_y</th>\n",
       "      <th>p7_x</th>\n",
       "      <th>p7_y</th>\n",
       "      <th>p8_x</th>\n",
       "      <th>p8_y</th>\n",
       "      <th>p9_x</th>\n",
       "      <th>p9_y</th>\n",
       "      <th>p10_x</th>\n",
       "      <th>p10_y</th>\n",
       "      <th>p11_x</th>\n",
       "      <th>p11_y</th>\n",
       "      <th>p12_x</th>\n",
       "      <th>p12_y</th>\n",
       "      <th>p13_x</th>\n",
       "      <th>p13_y</th>\n",
       "      <th>p14_x</th>\n",
       "      <th>p14_y</th>\n",
       "      <th>p15_x</th>\n",
       "      <th>p15_y</th>\n",
       "      <th>p16_x</th>\n",
       "      <th>p16_y</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>83.2</td>\n",
       "      <td>83.2</td>\n",
       "      <td>66.6</td>\n",
       "      <td>57.1</td>\n",
       "      <td>250.6</td>\n",
       "      <td>252.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.486772</td>\n",
       "      <td>0.122603</td>\n",
       "      <td>0.824980</td>\n",
       "      <td>0.335509</td>\n",
       "      <td>0.832723</td>\n",
       "      <td>0.685898</td>\n",
       "      <td>0.496715</td>\n",
       "      <td>0.950725</td>\n",
       "      <td>0.165411</td>\n",
       "      <td>0.694735</td>\n",
       "      <td>0.467072</td>\n",
       "      <td>0.247196</td>\n",
       "      <td>0.457011</td>\n",
       "      <td>0.396566</td>\n",
       "      <td>0.450612</td>\n",
       "      <td>0.526023</td>\n",
       "      <td>0.459656</td>\n",
       "      <td>0.655509</td>\n",
       "      <td>0.475720</td>\n",
       "      <td>0.802080</td>\n",
       "      <td>0.520294</td>\n",
       "      <td>0.814611</td>\n",
       "      <td>0.532672</td>\n",
       "      <td>0.663148</td>\n",
       "      <td>0.538515</td>\n",
       "      <td>0.535099</td>\n",
       "      <td>0.528032</td>\n",
       "      <td>0.406524</td>\n",
       "      <td>0.510347</td>\n",
       "      <td>0.261392</td>\n",
       "      <td>chicken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>77.8</td>\n",
       "      <td>87.9</td>\n",
       "      <td>62.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>268.7</td>\n",
       "      <td>269.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.482807</td>\n",
       "      <td>0.125205</td>\n",
       "      <td>0.810595</td>\n",
       "      <td>0.342980</td>\n",
       "      <td>0.817371</td>\n",
       "      <td>0.672976</td>\n",
       "      <td>0.493479</td>\n",
       "      <td>0.947772</td>\n",
       "      <td>0.158876</td>\n",
       "      <td>0.719923</td>\n",
       "      <td>0.460517</td>\n",
       "      <td>0.248830</td>\n",
       "      <td>0.448322</td>\n",
       "      <td>0.398315</td>\n",
       "      <td>0.441560</td>\n",
       "      <td>0.527047</td>\n",
       "      <td>0.451084</td>\n",
       "      <td>0.655789</td>\n",
       "      <td>0.469036</td>\n",
       "      <td>0.801835</td>\n",
       "      <td>0.511638</td>\n",
       "      <td>0.815946</td>\n",
       "      <td>0.520894</td>\n",
       "      <td>0.664182</td>\n",
       "      <td>0.526259</td>\n",
       "      <td>0.534747</td>\n",
       "      <td>0.516774</td>\n",
       "      <td>0.405286</td>\n",
       "      <td>0.501774</td>\n",
       "      <td>0.260312</td>\n",
       "      <td>chicken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>89.2</td>\n",
       "      <td>76.7</td>\n",
       "      <td>34.9</td>\n",
       "      <td>50.4</td>\n",
       "      <td>289.2</td>\n",
       "      <td>290.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.487183</td>\n",
       "      <td>0.126480</td>\n",
       "      <td>0.823707</td>\n",
       "      <td>0.333231</td>\n",
       "      <td>0.830686</td>\n",
       "      <td>0.684766</td>\n",
       "      <td>0.495617</td>\n",
       "      <td>0.947357</td>\n",
       "      <td>0.165857</td>\n",
       "      <td>0.699332</td>\n",
       "      <td>0.468062</td>\n",
       "      <td>0.248469</td>\n",
       "      <td>0.458380</td>\n",
       "      <td>0.397180</td>\n",
       "      <td>0.451829</td>\n",
       "      <td>0.526704</td>\n",
       "      <td>0.460272</td>\n",
       "      <td>0.656193</td>\n",
       "      <td>0.475453</td>\n",
       "      <td>0.802077</td>\n",
       "      <td>0.519133</td>\n",
       "      <td>0.814081</td>\n",
       "      <td>0.531606</td>\n",
       "      <td>0.662869</td>\n",
       "      <td>0.537763</td>\n",
       "      <td>0.534894</td>\n",
       "      <td>0.527670</td>\n",
       "      <td>0.406628</td>\n",
       "      <td>0.510563</td>\n",
       "      <td>0.262032</td>\n",
       "      <td>chicken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>83.1</td>\n",
       "      <td>83.2</td>\n",
       "      <td>58.4</td>\n",
       "      <td>39.7</td>\n",
       "      <td>290.4</td>\n",
       "      <td>291.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.483630</td>\n",
       "      <td>0.117559</td>\n",
       "      <td>0.814050</td>\n",
       "      <td>0.342752</td>\n",
       "      <td>0.821979</td>\n",
       "      <td>0.679094</td>\n",
       "      <td>0.494035</td>\n",
       "      <td>0.949543</td>\n",
       "      <td>0.160134</td>\n",
       "      <td>0.704046</td>\n",
       "      <td>0.462099</td>\n",
       "      <td>0.245541</td>\n",
       "      <td>0.450450</td>\n",
       "      <td>0.396034</td>\n",
       "      <td>0.443983</td>\n",
       "      <td>0.525266</td>\n",
       "      <td>0.453578</td>\n",
       "      <td>0.653920</td>\n",
       "      <td>0.471116</td>\n",
       "      <td>0.800047</td>\n",
       "      <td>0.514464</td>\n",
       "      <td>0.814155</td>\n",
       "      <td>0.525114</td>\n",
       "      <td>0.662799</td>\n",
       "      <td>0.530718</td>\n",
       "      <td>0.534543</td>\n",
       "      <td>0.520653</td>\n",
       "      <td>0.405218</td>\n",
       "      <td>0.504291</td>\n",
       "      <td>0.258725</td>\n",
       "      <td>chicken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>81.7</td>\n",
       "      <td>83.4</td>\n",
       "      <td>38.5</td>\n",
       "      <td>57.2</td>\n",
       "      <td>283.6</td>\n",
       "      <td>283.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.484814</td>\n",
       "      <td>0.118957</td>\n",
       "      <td>0.812235</td>\n",
       "      <td>0.338922</td>\n",
       "      <td>0.817982</td>\n",
       "      <td>0.671003</td>\n",
       "      <td>0.493289</td>\n",
       "      <td>0.946306</td>\n",
       "      <td>0.159463</td>\n",
       "      <td>0.725300</td>\n",
       "      <td>0.462570</td>\n",
       "      <td>0.247857</td>\n",
       "      <td>0.449551</td>\n",
       "      <td>0.398468</td>\n",
       "      <td>0.442434</td>\n",
       "      <td>0.527252</td>\n",
       "      <td>0.451574</td>\n",
       "      <td>0.655475</td>\n",
       "      <td>0.469117</td>\n",
       "      <td>0.800978</td>\n",
       "      <td>0.511902</td>\n",
       "      <td>0.814844</td>\n",
       "      <td>0.522257</td>\n",
       "      <td>0.662937</td>\n",
       "      <td>0.528531</td>\n",
       "      <td>0.534029</td>\n",
       "      <td>0.519374</td>\n",
       "      <td>0.404832</td>\n",
       "      <td>0.503818</td>\n",
       "      <td>0.258941</td>\n",
       "      <td>chicken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>92.0</td>\n",
       "      <td>74.4</td>\n",
       "      <td>58.6</td>\n",
       "      <td>53.2</td>\n",
       "      <td>280.7</td>\n",
       "      <td>280.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.486033</td>\n",
       "      <td>0.125645</td>\n",
       "      <td>0.821760</td>\n",
       "      <td>0.334590</td>\n",
       "      <td>0.830365</td>\n",
       "      <td>0.689392</td>\n",
       "      <td>0.496982</td>\n",
       "      <td>0.937005</td>\n",
       "      <td>0.166233</td>\n",
       "      <td>0.695723</td>\n",
       "      <td>0.467945</td>\n",
       "      <td>0.245026</td>\n",
       "      <td>0.459733</td>\n",
       "      <td>0.393832</td>\n",
       "      <td>0.454177</td>\n",
       "      <td>0.523335</td>\n",
       "      <td>0.463035</td>\n",
       "      <td>0.652851</td>\n",
       "      <td>0.477921</td>\n",
       "      <td>0.798021</td>\n",
       "      <td>0.518934</td>\n",
       "      <td>0.811307</td>\n",
       "      <td>0.529753</td>\n",
       "      <td>0.661560</td>\n",
       "      <td>0.535287</td>\n",
       "      <td>0.533565</td>\n",
       "      <td>0.525243</td>\n",
       "      <td>0.405092</td>\n",
       "      <td>0.508569</td>\n",
       "      <td>0.260399</td>\n",
       "      <td>chicken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>102.6</td>\n",
       "      <td>83.8</td>\n",
       "      <td>68.4</td>\n",
       "      <td>42.4</td>\n",
       "      <td>288.1</td>\n",
       "      <td>289.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.486772</td>\n",
       "      <td>0.111661</td>\n",
       "      <td>0.825958</td>\n",
       "      <td>0.336497</td>\n",
       "      <td>0.834363</td>\n",
       "      <td>0.700434</td>\n",
       "      <td>0.497142</td>\n",
       "      <td>0.952099</td>\n",
       "      <td>0.168112</td>\n",
       "      <td>0.686389</td>\n",
       "      <td>0.468440</td>\n",
       "      <td>0.243501</td>\n",
       "      <td>0.458644</td>\n",
       "      <td>0.394361</td>\n",
       "      <td>0.452864</td>\n",
       "      <td>0.523365</td>\n",
       "      <td>0.462593</td>\n",
       "      <td>0.652811</td>\n",
       "      <td>0.478321</td>\n",
       "      <td>0.800284</td>\n",
       "      <td>0.521959</td>\n",
       "      <td>0.813593</td>\n",
       "      <td>0.535944</td>\n",
       "      <td>0.661625</td>\n",
       "      <td>0.542310</td>\n",
       "      <td>0.534018</td>\n",
       "      <td>0.531212</td>\n",
       "      <td>0.405959</td>\n",
       "      <td>0.511510</td>\n",
       "      <td>0.259022</td>\n",
       "      <td>egg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>94.6</td>\n",
       "      <td>92.6</td>\n",
       "      <td>70.5</td>\n",
       "      <td>55.9</td>\n",
       "      <td>316.9</td>\n",
       "      <td>318.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.483136</td>\n",
       "      <td>0.113313</td>\n",
       "      <td>0.812407</td>\n",
       "      <td>0.350372</td>\n",
       "      <td>0.820421</td>\n",
       "      <td>0.680903</td>\n",
       "      <td>0.493432</td>\n",
       "      <td>0.952571</td>\n",
       "      <td>0.160321</td>\n",
       "      <td>0.702460</td>\n",
       "      <td>0.460304</td>\n",
       "      <td>0.244967</td>\n",
       "      <td>0.447562</td>\n",
       "      <td>0.395735</td>\n",
       "      <td>0.441067</td>\n",
       "      <td>0.524272</td>\n",
       "      <td>0.451330</td>\n",
       "      <td>0.652402</td>\n",
       "      <td>0.469842</td>\n",
       "      <td>0.798923</td>\n",
       "      <td>0.513824</td>\n",
       "      <td>0.814553</td>\n",
       "      <td>0.524736</td>\n",
       "      <td>0.662869</td>\n",
       "      <td>0.530357</td>\n",
       "      <td>0.534691</td>\n",
       "      <td>0.520004</td>\n",
       "      <td>0.405408</td>\n",
       "      <td>0.503253</td>\n",
       "      <td>0.258135</td>\n",
       "      <td>egg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>97.8</td>\n",
       "      <td>89.1</td>\n",
       "      <td>57.4</td>\n",
       "      <td>61.2</td>\n",
       "      <td>316.9</td>\n",
       "      <td>316.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.485698</td>\n",
       "      <td>0.114515</td>\n",
       "      <td>0.815838</td>\n",
       "      <td>0.339680</td>\n",
       "      <td>0.819963</td>\n",
       "      <td>0.670277</td>\n",
       "      <td>0.493544</td>\n",
       "      <td>0.953249</td>\n",
       "      <td>0.160844</td>\n",
       "      <td>0.719782</td>\n",
       "      <td>0.463858</td>\n",
       "      <td>0.247365</td>\n",
       "      <td>0.450646</td>\n",
       "      <td>0.398651</td>\n",
       "      <td>0.443337</td>\n",
       "      <td>0.527345</td>\n",
       "      <td>0.452460</td>\n",
       "      <td>0.655599</td>\n",
       "      <td>0.469943</td>\n",
       "      <td>0.801924</td>\n",
       "      <td>0.513242</td>\n",
       "      <td>0.815043</td>\n",
       "      <td>0.524845</td>\n",
       "      <td>0.662337</td>\n",
       "      <td>0.531427</td>\n",
       "      <td>0.533712</td>\n",
       "      <td>0.521991</td>\n",
       "      <td>0.404857</td>\n",
       "      <td>0.505578</td>\n",
       "      <td>0.258527</td>\n",
       "      <td>egg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>95.0</td>\n",
       "      <td>91.8</td>\n",
       "      <td>59.6</td>\n",
       "      <td>56.8</td>\n",
       "      <td>313.3</td>\n",
       "      <td>315.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.485038</td>\n",
       "      <td>0.112642</td>\n",
       "      <td>0.814746</td>\n",
       "      <td>0.340455</td>\n",
       "      <td>0.818579</td>\n",
       "      <td>0.667882</td>\n",
       "      <td>0.493339</td>\n",
       "      <td>0.953045</td>\n",
       "      <td>0.160216</td>\n",
       "      <td>0.725208</td>\n",
       "      <td>0.462528</td>\n",
       "      <td>0.247156</td>\n",
       "      <td>0.448692</td>\n",
       "      <td>0.398948</td>\n",
       "      <td>0.441324</td>\n",
       "      <td>0.527601</td>\n",
       "      <td>0.450697</td>\n",
       "      <td>0.655617</td>\n",
       "      <td>0.468813</td>\n",
       "      <td>0.801753</td>\n",
       "      <td>0.512330</td>\n",
       "      <td>0.815220</td>\n",
       "      <td>0.523693</td>\n",
       "      <td>0.662386</td>\n",
       "      <td>0.530298</td>\n",
       "      <td>0.533556</td>\n",
       "      <td>0.520881</td>\n",
       "      <td>0.404465</td>\n",
       "      <td>0.504472</td>\n",
       "      <td>0.257735</td>\n",
       "      <td>egg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>103.4</td>\n",
       "      <td>84.0</td>\n",
       "      <td>54.3</td>\n",
       "      <td>51.5</td>\n",
       "      <td>288.8</td>\n",
       "      <td>291.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.486138</td>\n",
       "      <td>0.118378</td>\n",
       "      <td>0.818006</td>\n",
       "      <td>0.336259</td>\n",
       "      <td>0.823421</td>\n",
       "      <td>0.679768</td>\n",
       "      <td>0.493873</td>\n",
       "      <td>0.946138</td>\n",
       "      <td>0.163848</td>\n",
       "      <td>0.700925</td>\n",
       "      <td>0.466323</td>\n",
       "      <td>0.245382</td>\n",
       "      <td>0.455509</td>\n",
       "      <td>0.395559</td>\n",
       "      <td>0.448891</td>\n",
       "      <td>0.524912</td>\n",
       "      <td>0.457615</td>\n",
       "      <td>0.653657</td>\n",
       "      <td>0.473305</td>\n",
       "      <td>0.799389</td>\n",
       "      <td>0.515329</td>\n",
       "      <td>0.812716</td>\n",
       "      <td>0.526936</td>\n",
       "      <td>0.661516</td>\n",
       "      <td>0.533236</td>\n",
       "      <td>0.533625</td>\n",
       "      <td>0.523618</td>\n",
       "      <td>0.404883</td>\n",
       "      <td>0.507206</td>\n",
       "      <td>0.258860</td>\n",
       "      <td>egg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>100.7</td>\n",
       "      <td>86.0</td>\n",
       "      <td>51.8</td>\n",
       "      <td>56.1</td>\n",
       "      <td>297.9</td>\n",
       "      <td>299.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.485711</td>\n",
       "      <td>0.117682</td>\n",
       "      <td>0.815888</td>\n",
       "      <td>0.337967</td>\n",
       "      <td>0.820182</td>\n",
       "      <td>0.676334</td>\n",
       "      <td>0.492954</td>\n",
       "      <td>0.946780</td>\n",
       "      <td>0.161371</td>\n",
       "      <td>0.706382</td>\n",
       "      <td>0.465176</td>\n",
       "      <td>0.246019</td>\n",
       "      <td>0.453517</td>\n",
       "      <td>0.396437</td>\n",
       "      <td>0.446633</td>\n",
       "      <td>0.525503</td>\n",
       "      <td>0.455407</td>\n",
       "      <td>0.653933</td>\n",
       "      <td>0.471515</td>\n",
       "      <td>0.799645</td>\n",
       "      <td>0.513447</td>\n",
       "      <td>0.813059</td>\n",
       "      <td>0.524729</td>\n",
       "      <td>0.661666</td>\n",
       "      <td>0.531149</td>\n",
       "      <td>0.533590</td>\n",
       "      <td>0.521819</td>\n",
       "      <td>0.404809</td>\n",
       "      <td>0.505855</td>\n",
       "      <td>0.258792</td>\n",
       "      <td>egg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>104.4</td>\n",
       "      <td>93.1</td>\n",
       "      <td>59.2</td>\n",
       "      <td>47.3</td>\n",
       "      <td>295.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.486419</td>\n",
       "      <td>0.110784</td>\n",
       "      <td>0.823884</td>\n",
       "      <td>0.337817</td>\n",
       "      <td>0.833273</td>\n",
       "      <td>0.685765</td>\n",
       "      <td>0.497178</td>\n",
       "      <td>0.953182</td>\n",
       "      <td>0.164438</td>\n",
       "      <td>0.691120</td>\n",
       "      <td>0.466573</td>\n",
       "      <td>0.244381</td>\n",
       "      <td>0.455201</td>\n",
       "      <td>0.395285</td>\n",
       "      <td>0.448825</td>\n",
       "      <td>0.523988</td>\n",
       "      <td>0.458676</td>\n",
       "      <td>0.652839</td>\n",
       "      <td>0.475856</td>\n",
       "      <td>0.800188</td>\n",
       "      <td>0.520800</td>\n",
       "      <td>0.812465</td>\n",
       "      <td>0.534409</td>\n",
       "      <td>0.660048</td>\n",
       "      <td>0.540782</td>\n",
       "      <td>0.532634</td>\n",
       "      <td>0.529795</td>\n",
       "      <td>0.404662</td>\n",
       "      <td>0.510462</td>\n",
       "      <td>0.258080</td>\n",
       "      <td>tomato</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>99.2</td>\n",
       "      <td>98.9</td>\n",
       "      <td>61.3</td>\n",
       "      <td>47.7</td>\n",
       "      <td>309.8</td>\n",
       "      <td>310.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.484283</td>\n",
       "      <td>0.110617</td>\n",
       "      <td>0.812656</td>\n",
       "      <td>0.345082</td>\n",
       "      <td>0.819490</td>\n",
       "      <td>0.673026</td>\n",
       "      <td>0.494051</td>\n",
       "      <td>0.953924</td>\n",
       "      <td>0.159321</td>\n",
       "      <td>0.713467</td>\n",
       "      <td>0.461191</td>\n",
       "      <td>0.245703</td>\n",
       "      <td>0.447182</td>\n",
       "      <td>0.397473</td>\n",
       "      <td>0.440093</td>\n",
       "      <td>0.526059</td>\n",
       "      <td>0.450163</td>\n",
       "      <td>0.654105</td>\n",
       "      <td>0.469177</td>\n",
       "      <td>0.800708</td>\n",
       "      <td>0.513874</td>\n",
       "      <td>0.814629</td>\n",
       "      <td>0.525442</td>\n",
       "      <td>0.661890</td>\n",
       "      <td>0.531712</td>\n",
       "      <td>0.533471</td>\n",
       "      <td>0.521589</td>\n",
       "      <td>0.404395</td>\n",
       "      <td>0.504460</td>\n",
       "      <td>0.257037</td>\n",
       "      <td>tomato</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>104.4</td>\n",
       "      <td>94.9</td>\n",
       "      <td>56.3</td>\n",
       "      <td>61.1</td>\n",
       "      <td>329.5</td>\n",
       "      <td>330.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.484991</td>\n",
       "      <td>0.108934</td>\n",
       "      <td>0.816635</td>\n",
       "      <td>0.341322</td>\n",
       "      <td>0.823717</td>\n",
       "      <td>0.674976</td>\n",
       "      <td>0.494407</td>\n",
       "      <td>0.955296</td>\n",
       "      <td>0.160671</td>\n",
       "      <td>0.704568</td>\n",
       "      <td>0.463649</td>\n",
       "      <td>0.245130</td>\n",
       "      <td>0.450466</td>\n",
       "      <td>0.396849</td>\n",
       "      <td>0.443419</td>\n",
       "      <td>0.525430</td>\n",
       "      <td>0.453190</td>\n",
       "      <td>0.653567</td>\n",
       "      <td>0.471347</td>\n",
       "      <td>0.800680</td>\n",
       "      <td>0.515310</td>\n",
       "      <td>0.813499</td>\n",
       "      <td>0.527808</td>\n",
       "      <td>0.660564</td>\n",
       "      <td>0.534289</td>\n",
       "      <td>0.532734</td>\n",
       "      <td>0.524005</td>\n",
       "      <td>0.404222</td>\n",
       "      <td>0.506157</td>\n",
       "      <td>0.257068</td>\n",
       "      <td>tomato</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>115.9</td>\n",
       "      <td>83.2</td>\n",
       "      <td>53.5</td>\n",
       "      <td>43.9</td>\n",
       "      <td>336.4</td>\n",
       "      <td>334.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.487909</td>\n",
       "      <td>0.114650</td>\n",
       "      <td>0.826863</td>\n",
       "      <td>0.327314</td>\n",
       "      <td>0.834269</td>\n",
       "      <td>0.698923</td>\n",
       "      <td>0.498096</td>\n",
       "      <td>0.948627</td>\n",
       "      <td>0.169647</td>\n",
       "      <td>0.686114</td>\n",
       "      <td>0.470466</td>\n",
       "      <td>0.242857</td>\n",
       "      <td>0.461128</td>\n",
       "      <td>0.393686</td>\n",
       "      <td>0.455154</td>\n",
       "      <td>0.522877</td>\n",
       "      <td>0.464587</td>\n",
       "      <td>0.652298</td>\n",
       "      <td>0.480037</td>\n",
       "      <td>0.799513</td>\n",
       "      <td>0.523104</td>\n",
       "      <td>0.811209</td>\n",
       "      <td>0.537276</td>\n",
       "      <td>0.659656</td>\n",
       "      <td>0.543741</td>\n",
       "      <td>0.532200</td>\n",
       "      <td>0.532848</td>\n",
       "      <td>0.404438</td>\n",
       "      <td>0.513320</td>\n",
       "      <td>0.258462</td>\n",
       "      <td>tomato</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>103.6</td>\n",
       "      <td>96.1</td>\n",
       "      <td>61.5</td>\n",
       "      <td>55.7</td>\n",
       "      <td>329.2</td>\n",
       "      <td>331.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.483965</td>\n",
       "      <td>0.110832</td>\n",
       "      <td>0.813530</td>\n",
       "      <td>0.342630</td>\n",
       "      <td>0.820081</td>\n",
       "      <td>0.674562</td>\n",
       "      <td>0.493827</td>\n",
       "      <td>0.952794</td>\n",
       "      <td>0.159780</td>\n",
       "      <td>0.709513</td>\n",
       "      <td>0.462186</td>\n",
       "      <td>0.245510</td>\n",
       "      <td>0.448914</td>\n",
       "      <td>0.397081</td>\n",
       "      <td>0.441968</td>\n",
       "      <td>0.525470</td>\n",
       "      <td>0.451887</td>\n",
       "      <td>0.653470</td>\n",
       "      <td>0.470272</td>\n",
       "      <td>0.800143</td>\n",
       "      <td>0.513604</td>\n",
       "      <td>0.813609</td>\n",
       "      <td>0.525234</td>\n",
       "      <td>0.661019</td>\n",
       "      <td>0.531524</td>\n",
       "      <td>0.532780</td>\n",
       "      <td>0.521469</td>\n",
       "      <td>0.404057</td>\n",
       "      <td>0.504292</td>\n",
       "      <td>0.257122</td>\n",
       "      <td>tomato</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>109.4</td>\n",
       "      <td>89.3</td>\n",
       "      <td>60.6</td>\n",
       "      <td>61.0</td>\n",
       "      <td>292.5</td>\n",
       "      <td>294.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.486663</td>\n",
       "      <td>0.112810</td>\n",
       "      <td>0.821785</td>\n",
       "      <td>0.337476</td>\n",
       "      <td>0.830089</td>\n",
       "      <td>0.684160</td>\n",
       "      <td>0.496799</td>\n",
       "      <td>0.951509</td>\n",
       "      <td>0.164925</td>\n",
       "      <td>0.693852</td>\n",
       "      <td>0.466836</td>\n",
       "      <td>0.244573</td>\n",
       "      <td>0.455702</td>\n",
       "      <td>0.395580</td>\n",
       "      <td>0.449257</td>\n",
       "      <td>0.524899</td>\n",
       "      <td>0.458737</td>\n",
       "      <td>0.653989</td>\n",
       "      <td>0.475510</td>\n",
       "      <td>0.800983</td>\n",
       "      <td>0.519789</td>\n",
       "      <td>0.813247</td>\n",
       "      <td>0.532645</td>\n",
       "      <td>0.661095</td>\n",
       "      <td>0.538888</td>\n",
       "      <td>0.533303</td>\n",
       "      <td>0.528288</td>\n",
       "      <td>0.404755</td>\n",
       "      <td>0.509913</td>\n",
       "      <td>0.258024</td>\n",
       "      <td>tomato</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    weight_reading_1  weight_reading_2  pressure_reading_1  \\\n",
       "0               83.2              83.2                66.6   \n",
       "1               77.8              87.9                62.0   \n",
       "2               89.2              76.7                34.9   \n",
       "3               83.1              83.2                58.4   \n",
       "4               81.7              83.4                38.5   \n",
       "5               92.0              74.4                58.6   \n",
       "6              102.6              83.8                68.4   \n",
       "7               94.6              92.6                70.5   \n",
       "8               97.8              89.1                57.4   \n",
       "9               95.0              91.8                59.6   \n",
       "10             103.4              84.0                54.3   \n",
       "11             100.7              86.0                51.8   \n",
       "12             104.4              93.1                59.2   \n",
       "13              99.2              98.9                61.3   \n",
       "14             104.4              94.9                56.3   \n",
       "15             115.9              83.2                53.5   \n",
       "16             103.6              96.1                61.5   \n",
       "17             109.4              89.3                60.6   \n",
       "\n",
       "    pressure_reading_2  force_reading_1  force_reading_2  p1_x  p1_y  \\\n",
       "0                 57.1            250.6            252.2   0.0   0.0   \n",
       "1                 66.0            268.7            269.3   0.0   0.0   \n",
       "2                 50.4            289.2            290.0   0.0   0.0   \n",
       "3                 39.7            290.4            291.2   0.0   0.0   \n",
       "4                 57.2            283.6            283.0   0.0   0.0   \n",
       "5                 53.2            280.7            280.6   0.0   0.0   \n",
       "6                 42.4            288.1            289.2   0.0   0.0   \n",
       "7                 55.9            316.9            318.8   0.0   0.0   \n",
       "8                 61.2            316.9            316.2   0.0   0.0   \n",
       "9                 56.8            313.3            315.2   0.0   0.0   \n",
       "10                51.5            288.8            291.1   0.0   0.0   \n",
       "11                56.1            297.9            299.4   0.0   0.0   \n",
       "12                47.3            295.0            296.0   0.0   0.0   \n",
       "13                47.7            309.8            310.7   0.0   0.0   \n",
       "14                61.1            329.5            330.9   0.0   0.0   \n",
       "15                43.9            336.4            334.3   0.0   0.0   \n",
       "16                55.7            329.2            331.2   0.0   0.0   \n",
       "17                61.0            292.5            294.3   0.0   0.0   \n",
       "\n",
       "        p2_x      p2_y      p3_x      p3_y      p4_x      p4_y      p5_x  \\\n",
       "0   0.486772  0.122603  0.824980  0.335509  0.832723  0.685898  0.496715   \n",
       "1   0.482807  0.125205  0.810595  0.342980  0.817371  0.672976  0.493479   \n",
       "2   0.487183  0.126480  0.823707  0.333231  0.830686  0.684766  0.495617   \n",
       "3   0.483630  0.117559  0.814050  0.342752  0.821979  0.679094  0.494035   \n",
       "4   0.484814  0.118957  0.812235  0.338922  0.817982  0.671003  0.493289   \n",
       "5   0.486033  0.125645  0.821760  0.334590  0.830365  0.689392  0.496982   \n",
       "6   0.486772  0.111661  0.825958  0.336497  0.834363  0.700434  0.497142   \n",
       "7   0.483136  0.113313  0.812407  0.350372  0.820421  0.680903  0.493432   \n",
       "8   0.485698  0.114515  0.815838  0.339680  0.819963  0.670277  0.493544   \n",
       "9   0.485038  0.112642  0.814746  0.340455  0.818579  0.667882  0.493339   \n",
       "10  0.486138  0.118378  0.818006  0.336259  0.823421  0.679768  0.493873   \n",
       "11  0.485711  0.117682  0.815888  0.337967  0.820182  0.676334  0.492954   \n",
       "12  0.486419  0.110784  0.823884  0.337817  0.833273  0.685765  0.497178   \n",
       "13  0.484283  0.110617  0.812656  0.345082  0.819490  0.673026  0.494051   \n",
       "14  0.484991  0.108934  0.816635  0.341322  0.823717  0.674976  0.494407   \n",
       "15  0.487909  0.114650  0.826863  0.327314  0.834269  0.698923  0.498096   \n",
       "16  0.483965  0.110832  0.813530  0.342630  0.820081  0.674562  0.493827   \n",
       "17  0.486663  0.112810  0.821785  0.337476  0.830089  0.684160  0.496799   \n",
       "\n",
       "        p5_y      p6_x      p6_y      p7_x      p7_y      p8_x      p8_y  \\\n",
       "0   0.950725  0.165411  0.694735  0.467072  0.247196  0.457011  0.396566   \n",
       "1   0.947772  0.158876  0.719923  0.460517  0.248830  0.448322  0.398315   \n",
       "2   0.947357  0.165857  0.699332  0.468062  0.248469  0.458380  0.397180   \n",
       "3   0.949543  0.160134  0.704046  0.462099  0.245541  0.450450  0.396034   \n",
       "4   0.946306  0.159463  0.725300  0.462570  0.247857  0.449551  0.398468   \n",
       "5   0.937005  0.166233  0.695723  0.467945  0.245026  0.459733  0.393832   \n",
       "6   0.952099  0.168112  0.686389  0.468440  0.243501  0.458644  0.394361   \n",
       "7   0.952571  0.160321  0.702460  0.460304  0.244967  0.447562  0.395735   \n",
       "8   0.953249  0.160844  0.719782  0.463858  0.247365  0.450646  0.398651   \n",
       "9   0.953045  0.160216  0.725208  0.462528  0.247156  0.448692  0.398948   \n",
       "10  0.946138  0.163848  0.700925  0.466323  0.245382  0.455509  0.395559   \n",
       "11  0.946780  0.161371  0.706382  0.465176  0.246019  0.453517  0.396437   \n",
       "12  0.953182  0.164438  0.691120  0.466573  0.244381  0.455201  0.395285   \n",
       "13  0.953924  0.159321  0.713467  0.461191  0.245703  0.447182  0.397473   \n",
       "14  0.955296  0.160671  0.704568  0.463649  0.245130  0.450466  0.396849   \n",
       "15  0.948627  0.169647  0.686114  0.470466  0.242857  0.461128  0.393686   \n",
       "16  0.952794  0.159780  0.709513  0.462186  0.245510  0.448914  0.397081   \n",
       "17  0.951509  0.164925  0.693852  0.466836  0.244573  0.455702  0.395580   \n",
       "\n",
       "        p9_x      p9_y     p10_x     p10_y     p11_x     p11_y     p12_x  \\\n",
       "0   0.450612  0.526023  0.459656  0.655509  0.475720  0.802080  0.520294   \n",
       "1   0.441560  0.527047  0.451084  0.655789  0.469036  0.801835  0.511638   \n",
       "2   0.451829  0.526704  0.460272  0.656193  0.475453  0.802077  0.519133   \n",
       "3   0.443983  0.525266  0.453578  0.653920  0.471116  0.800047  0.514464   \n",
       "4   0.442434  0.527252  0.451574  0.655475  0.469117  0.800978  0.511902   \n",
       "5   0.454177  0.523335  0.463035  0.652851  0.477921  0.798021  0.518934   \n",
       "6   0.452864  0.523365  0.462593  0.652811  0.478321  0.800284  0.521959   \n",
       "7   0.441067  0.524272  0.451330  0.652402  0.469842  0.798923  0.513824   \n",
       "8   0.443337  0.527345  0.452460  0.655599  0.469943  0.801924  0.513242   \n",
       "9   0.441324  0.527601  0.450697  0.655617  0.468813  0.801753  0.512330   \n",
       "10  0.448891  0.524912  0.457615  0.653657  0.473305  0.799389  0.515329   \n",
       "11  0.446633  0.525503  0.455407  0.653933  0.471515  0.799645  0.513447   \n",
       "12  0.448825  0.523988  0.458676  0.652839  0.475856  0.800188  0.520800   \n",
       "13  0.440093  0.526059  0.450163  0.654105  0.469177  0.800708  0.513874   \n",
       "14  0.443419  0.525430  0.453190  0.653567  0.471347  0.800680  0.515310   \n",
       "15  0.455154  0.522877  0.464587  0.652298  0.480037  0.799513  0.523104   \n",
       "16  0.441968  0.525470  0.451887  0.653470  0.470272  0.800143  0.513604   \n",
       "17  0.449257  0.524899  0.458737  0.653989  0.475510  0.800983  0.519789   \n",
       "\n",
       "       p12_y     p13_x     p13_y     p14_x     p14_y     p15_x     p15_y  \\\n",
       "0   0.814611  0.532672  0.663148  0.538515  0.535099  0.528032  0.406524   \n",
       "1   0.815946  0.520894  0.664182  0.526259  0.534747  0.516774  0.405286   \n",
       "2   0.814081  0.531606  0.662869  0.537763  0.534894  0.527670  0.406628   \n",
       "3   0.814155  0.525114  0.662799  0.530718  0.534543  0.520653  0.405218   \n",
       "4   0.814844  0.522257  0.662937  0.528531  0.534029  0.519374  0.404832   \n",
       "5   0.811307  0.529753  0.661560  0.535287  0.533565  0.525243  0.405092   \n",
       "6   0.813593  0.535944  0.661625  0.542310  0.534018  0.531212  0.405959   \n",
       "7   0.814553  0.524736  0.662869  0.530357  0.534691  0.520004  0.405408   \n",
       "8   0.815043  0.524845  0.662337  0.531427  0.533712  0.521991  0.404857   \n",
       "9   0.815220  0.523693  0.662386  0.530298  0.533556  0.520881  0.404465   \n",
       "10  0.812716  0.526936  0.661516  0.533236  0.533625  0.523618  0.404883   \n",
       "11  0.813059  0.524729  0.661666  0.531149  0.533590  0.521819  0.404809   \n",
       "12  0.812465  0.534409  0.660048  0.540782  0.532634  0.529795  0.404662   \n",
       "13  0.814629  0.525442  0.661890  0.531712  0.533471  0.521589  0.404395   \n",
       "14  0.813499  0.527808  0.660564  0.534289  0.532734  0.524005  0.404222   \n",
       "15  0.811209  0.537276  0.659656  0.543741  0.532200  0.532848  0.404438   \n",
       "16  0.813609  0.525234  0.661019  0.531524  0.532780  0.521469  0.404057   \n",
       "17  0.813247  0.532645  0.661095  0.538888  0.533303  0.528288  0.404755   \n",
       "\n",
       "       p16_x     p16_y    label  \n",
       "0   0.510347  0.261392  chicken  \n",
       "1   0.501774  0.260312  chicken  \n",
       "2   0.510563  0.262032  chicken  \n",
       "3   0.504291  0.258725  chicken  \n",
       "4   0.503818  0.258941  chicken  \n",
       "5   0.508569  0.260399  chicken  \n",
       "6   0.511510  0.259022      egg  \n",
       "7   0.503253  0.258135      egg  \n",
       "8   0.505578  0.258527      egg  \n",
       "9   0.504472  0.257735      egg  \n",
       "10  0.507206  0.258860      egg  \n",
       "11  0.505855  0.258792      egg  \n",
       "12  0.510462  0.258080   tomato  \n",
       "13  0.504460  0.257037   tomato  \n",
       "14  0.506157  0.257068   tomato  \n",
       "15  0.513320  0.258462   tomato  \n",
       "16  0.504292  0.257122   tomato  \n",
       "17  0.509913  0.258024   tomato  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grasp_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b36152f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grasp_dataset.to_csv('/home/dell/Desktop/xxxx/Uni/Kirigami_project/Keypoint_detection_notebooks/Grasp_dataset_3/' + 'validation_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b8afcd06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   weight_reading_1  weight_reading_2  pressure_reading_1  pressure_reading_2  \\\n",
      "0            0.0832            0.0832               0.666               0.571   \n",
      "1            0.0778            0.0879               0.620               0.660   \n",
      "\n",
      "   force_reading_1  force_reading_2  p1_x  p1_y      p2_x      p2_y      p3_x  \\\n",
      "0           0.2506           0.2522   0.0   0.0  0.486772  0.122603  0.824980   \n",
      "1           0.2687           0.2693   0.0   0.0  0.482807  0.125205  0.810595   \n",
      "\n",
      "       p3_y      p4_x      p4_y      p5_x      p5_y      p6_x      p6_y  \\\n",
      "0  0.335509  0.832723  0.685898  0.496715  0.950725  0.165411  0.694735   \n",
      "1  0.342980  0.817371  0.672976  0.493479  0.947772  0.158876  0.719923   \n",
      "\n",
      "       p7_x      p7_y      p8_x      p8_y      p9_x      p9_y     p10_x  \\\n",
      "0  0.467072  0.247196  0.457011  0.396566  0.450612  0.526023  0.459656   \n",
      "1  0.460517  0.248830  0.448322  0.398315  0.441560  0.527047  0.451084   \n",
      "\n",
      "      p10_y     p11_x     p11_y     p12_x     p12_y     p13_x     p13_y  \\\n",
      "0  0.655509  0.475720  0.802080  0.520294  0.814611  0.532672  0.663148   \n",
      "1  0.655789  0.469036  0.801835  0.511638  0.815946  0.520894  0.664182   \n",
      "\n",
      "      p14_x     p14_y     p15_x     p15_y     p16_x     p16_y  \n",
      "0  0.538515  0.535099  0.528032  0.406524  0.510347  0.261392  \n",
      "1  0.526259  0.534747  0.516774  0.405286  0.501774  0.260312  \n",
      "0    chicken\n",
      "1    chicken\n",
      "Name: label, dtype: object\n"
     ]
    }
   ],
   "source": [
    "grasp_data = grasp_dataset.drop(columns=['label'], axis=1)\n",
    "# grasp_data = grasp_dataset.drop(columns=['label', 'p1_x', 'p1_y', 'p2_x', 'p2_y', 'p3_x', 'p3_y', 'p4_x', 'p4_y', 'p5_x', 'p5_y', 'p6_x', 'p6_y', 'p7_x', 'p7_y', 'p8_x', 'p8_y', 'p9_x', 'p9_y', 'p10_x', 'p10_y', 'p11_x', 'p11_y', 'p12_x', 'p12_y', 'p13_x', 'p13_y', 'p14_x', 'p14_y', 'p15_x', 'p15_y', 'p16_x', 'p16_y'], axis=1)\n",
    "grasp_data['weight_reading_1'] = grasp_data['weight_reading_1'] / 1000\n",
    "grasp_data['weight_reading_2'] = grasp_data['weight_reading_2'] / 1000\n",
    "grasp_data['pressure_reading_1'] = grasp_data['pressure_reading_1'] / 100\n",
    "grasp_data['pressure_reading_2'] = grasp_data['pressure_reading_2'] / 100\n",
    "grasp_data['force_reading_1'] = grasp_data['force_reading_1'] / 1000\n",
    "grasp_data['force_reading_2'] = grasp_data['force_reading_2'] / 1000\n",
    "grasp_label = grasp_dataset['label']\n",
    "\n",
    "print(grasp_data.head(2))\n",
    "print(grasp_label.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1204b92c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         chicken  egg  tomato\n",
      "chicken        7    0       0\n",
      "egg            0   13       0\n",
      "tomato         0    4       9\n",
      "[[ 7  0  0]\n",
      " [ 0 13  0]\n",
      " [ 0  4  9]]\n",
      "Accuracy: 0.8787878787878788\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "data_train, data_test, label_train, label_test = train_test_split(grasp_data, grasp_label, test_size=0.2, random_state=np.random.randint(100))\n",
    "\n",
    "# print(X_train.head(3))\n",
    "\n",
    "# clf = KNeighborsClassifier(n_neighbors=7)\n",
    "\n",
    "# knn.fit(X_train, y_train)\n",
    "\n",
    "# y_pred = knn.predict(X_test)\n",
    "\n",
    "# accuracy = knn.score(X_test, y_test)\n",
    "# print('Accuracy:', accuracy)\n",
    "# clf = RandomForestClassifier(n_estimators=1000, max_depth=50, random_state=np.random.randint(100))\n",
    "clf = RandomForestClassifier(n_estimators=1000, max_depth=100, random_state=np.random.randint(100), n_jobs = -1)\n",
    "# clf = HistGradientBoostingClassifier(max_iter=200, random_state=np.random.randint(100))\n",
    "# clf = GradientBoostingClassifier(n_estimators=200, learning_rate=0.1, max_depth=1, random_state=0)\n",
    "# clf = VotingClassifier(estimators=[('lr', clf1), ('rf', clf2), ('gnb', clf3)],voting='hard')\n",
    "\n",
    "# num_folds = 10\n",
    "# cv_method = KFold(n_splits=num_folds, shuffle=True, random_state=np.random.randint(100))\n",
    "# cv_results = cross_val_score(clf, grasp_data, grasp_label, cv=cv_method, scoring='accuracy')\n",
    "\n",
    "# print('Cross-validation results:', cv_results)\n",
    "# print('Average accuracy:', cv_results.mean())\n",
    "\n",
    "clf.fit(data_train, label_train)\n",
    "label_pred = clf.predict(data_test)\n",
    "cm = confusion_matrix(label_test, label_pred)\n",
    "\n",
    "short_dataset_names = ['chicken', 'egg', 'tomato']\n",
    "\n",
    "\n",
    "cm_df = pd.DataFrame(cm, index=short_dataset_names, columns=short_dataset_names)\n",
    "\n",
    "print(cm_df)\n",
    "print(cm)\n",
    "\n",
    "accuracy = clf.score(data_test, label_test)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b9281437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['chicken' 'chicken' 'chicken' 'chicken' 'chicken' 'chicken' 'egg' 'egg'\n",
      " 'egg' 'egg' 'egg' 'egg' 'tomato' 'tomato' 'tomato' 'tomato' 'tomato'\n",
      " 'tomato']\n"
     ]
    }
   ],
   "source": [
    "label_pred = clf.predict(grasp_data)\n",
    "print(label_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9982fb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "Chicken, egg, tomato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f1bc14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d25dca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3427cdab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e672ddbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84543cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".Keypoint_detection_notebooks",
   "language": "python",
   "name": ".keypoint_detection_notebooks"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
