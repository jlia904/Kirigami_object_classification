{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8cbb8b46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dell/Desktop/xxxx/Uni/Kirigami_project/Keypoint_detection_notebooks/.Keypoint_detection_notebooks/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# importing relevant packages \n",
    "\n",
    "import torch \n",
    "from torchvision import models\n",
    "import pandas as pd\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn \n",
    "import glob\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt \n",
    "import torchvision.transforms as transforms\n",
    "from torchsummary import summary\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "205c2408",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db81ed4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = os. getcwd()\n",
    "images_dir = os.path.join(current_dir, 'Kirigami_dataset_2800')\n",
    "image_data = pd.read_csv(os.path.join(images_dir, 'Kirigami_dataset_2800.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "755745b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     image_name      p1_x      p1_y      p2_x      p2_y      p3_x      p3_y  \\\n",
      "0  image000.jpg  0.278689  0.375000  0.505464  0.283981  0.722222  0.416262   \n",
      "1  image001.jpg  0.192095  0.443210  0.422749  0.359039  0.636019  0.489254   \n",
      "2  image002.jpg  0.301376  0.553748  0.525652  0.465886  0.745770  0.600118   \n",
      "\n",
      "       p4_x      p4_y      p5_x  ...     p12_x     p12_y     p13_x     p13_y  \\\n",
      "0  0.722222  0.618932  0.495446  ...  0.534608  0.662621  0.551002  0.582524   \n",
      "1  0.637915  0.685209  0.415166  ...  0.456872  0.739570  0.470142  0.657396   \n",
      "2  0.754010  0.801074  0.512704  ...  0.558611  0.855238  0.572736  0.765750   \n",
      "\n",
      "      p14_x     p14_y     p15_x     p15_y     p16_x     p16_y  \n",
      "0  0.557377  0.507282  0.552823  0.439320  0.540984  0.360437  \n",
      "1  0.477725  0.581542  0.473934  0.510746  0.459716  0.432364  \n",
      "2  0.578622  0.691176  0.571559  0.617388  0.558611  0.538890  \n",
      "\n",
      "[3 rows x 33 columns]\n"
     ]
    }
   ],
   "source": [
    "print(image_data.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1b4e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_idx = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da77edd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_data.iloc[image_idx]['image_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde35fb3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# img_arr = cv2.imread(os.path.join(images_dir, image_data.iloc[image_idx]['image_name']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16cdbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158f31cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plt.imshow(img_arr)\n",
    "# x_points = image_data.iloc[image_idx][1:][::2]\n",
    "# y_points = image_data.iloc[image_idx][2:][::2]\n",
    "# x_width = img_arr.shape[1]\n",
    "# y_height = img_arr.shape[0]\n",
    "\n",
    "# plt.scatter(x_points*x_width, y_points*y_height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc7a2ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, df, img_dir):\n",
    "        self.df = df\n",
    "        self.img_dir = img_dir\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.df.iloc[idx, 0])\n",
    "        image = cv2.imread(img_path)\n",
    "        label = self.df.iloc[idx, 1:]\n",
    "        image = self.transform_image(image)\n",
    "        return image.to(device), torch.tensor(label).to(device)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "    \n",
    "    def transform_image(self, img):\n",
    "        img = cv2.resize(img, (224,224))\n",
    "        img_tensor = transforms.ToTensor()(img)\n",
    "        img_mean = img_tensor.mean(dim = (1,2))\n",
    "        img_std = img_tensor.std(dim = (1,2))\n",
    "        \n",
    "        img_normalised = transforms.Normalize(img_mean, img_std)(img_tensor)\n",
    "        return img_normalised\n",
    "    \n",
    "    def load_img(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.df.iloc[idx, 0])\n",
    "        img = cv2.imread(img_path)\n",
    "        return img\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28b6d6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(image_data, test_size=0.04)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06b12f0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2688, 33)\n",
      "(112, 33)\n"
     ]
    }
   ],
   "source": [
    "print(train_df.shape)\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f434fa17",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ImageDataset(train_df, images_dir)\n",
    "test_dataset = ImageDataset(test_df, images_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c02387cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "87baedba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VGG_model, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.LeakyReLU(0.1,inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.LeakyReLU(0.1,inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
    "            nn.Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.LeakyReLU(0.1,inplace=True),\n",
    "            nn.Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.LeakyReLU(0.1,inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
    "            nn.Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.LeakyReLU(0.1,inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.LeakyReLU(0.1,inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.LeakyReLU(0.1,inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
    "            nn.Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.LeakyReLU(0.1,inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.LeakyReLU(0.1,inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.LeakyReLU(0.1,inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
    "            nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.LeakyReLU(0.1,inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.LeakyReLU(0.1,inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "        )\n",
    "        \n",
    "        self.avgpool = nn.Sequential(\n",
    "             nn.Conv2d(512,512, kernel_size=3, padding='same'),\n",
    "             nn.LeakyReLU(0.1,inplace=True),\n",
    "             nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "             nn.Conv2d(512,50, kernel_size=3, padding='same'),\n",
    "             nn.LeakyReLU(0.1,inplace=True),\n",
    "             nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "             nn.AdaptiveAvgPool2d(output_size=(8,8))\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(3200, 300),\n",
    "            nn.LeakyReLU(0.1,inplace=True),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(300, 32),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "906c4d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VGG_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b56db79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f091071e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─Sequential: 1-1                        [-1, 512, 7, 7]           --\n",
      "|    └─Conv2d: 2-1                       [-1, 64, 224, 224]        1,792\n",
      "|    └─LeakyReLU: 2-2                    [-1, 64, 224, 224]        --\n",
      "|    └─Conv2d: 2-3                       [-1, 64, 224, 224]        36,928\n",
      "|    └─LeakyReLU: 2-4                    [-1, 64, 224, 224]        --\n",
      "|    └─MaxPool2d: 2-5                    [-1, 64, 112, 112]        --\n",
      "|    └─Conv2d: 2-6                       [-1, 128, 112, 112]       73,856\n",
      "|    └─LeakyReLU: 2-7                    [-1, 128, 112, 112]       --\n",
      "|    └─Conv2d: 2-8                       [-1, 128, 112, 112]       147,584\n",
      "|    └─LeakyReLU: 2-9                    [-1, 128, 112, 112]       --\n",
      "|    └─MaxPool2d: 2-10                   [-1, 128, 56, 56]         --\n",
      "|    └─Conv2d: 2-11                      [-1, 256, 56, 56]         295,168\n",
      "|    └─LeakyReLU: 2-12                   [-1, 256, 56, 56]         --\n",
      "|    └─Conv2d: 2-13                      [-1, 256, 56, 56]         590,080\n",
      "|    └─LeakyReLU: 2-14                   [-1, 256, 56, 56]         --\n",
      "|    └─Conv2d: 2-15                      [-1, 256, 56, 56]         590,080\n",
      "|    └─LeakyReLU: 2-16                   [-1, 256, 56, 56]         --\n",
      "|    └─MaxPool2d: 2-17                   [-1, 256, 28, 28]         --\n",
      "|    └─Conv2d: 2-18                      [-1, 512, 28, 28]         1,180,160\n",
      "|    └─LeakyReLU: 2-19                   [-1, 512, 28, 28]         --\n",
      "|    └─Conv2d: 2-20                      [-1, 512, 28, 28]         2,359,808\n",
      "|    └─LeakyReLU: 2-21                   [-1, 512, 28, 28]         --\n",
      "|    └─Conv2d: 2-22                      [-1, 512, 28, 28]         2,359,808\n",
      "|    └─LeakyReLU: 2-23                   [-1, 512, 28, 28]         --\n",
      "|    └─MaxPool2d: 2-24                   [-1, 512, 14, 14]         --\n",
      "|    └─Conv2d: 2-25                      [-1, 512, 14, 14]         2,359,808\n",
      "|    └─ReLU: 2-26                        [-1, 512, 14, 14]         --\n",
      "|    └─Conv2d: 2-27                      [-1, 512, 14, 14]         2,359,808\n",
      "|    └─LeakyReLU: 2-28                   [-1, 512, 14, 14]         --\n",
      "|    └─Conv2d: 2-29                      [-1, 512, 14, 14]         2,359,808\n",
      "|    └─LeakyReLU: 2-30                   [-1, 512, 14, 14]         --\n",
      "|    └─MaxPool2d: 2-31                   [-1, 512, 7, 7]           --\n",
      "├─Sequential: 1-2                        [-1, 50, 8, 8]            --\n",
      "|    └─Conv2d: 2-32                      [-1, 512, 7, 7]           2,359,808\n",
      "|    └─LeakyReLU: 2-33                   [-1, 512, 7, 7]           --\n",
      "|    └─MaxPool2d: 2-34                   [-1, 512, 3, 3]           --\n",
      "|    └─Conv2d: 2-35                      [-1, 50, 3, 3]            230,450\n",
      "|    └─LeakyReLU: 2-36                   [-1, 50, 3, 3]            --\n",
      "|    └─MaxPool2d: 2-37                   [-1, 50, 1, 1]            --\n",
      "|    └─AdaptiveAvgPool2d: 2-38           [-1, 50, 8, 8]            --\n",
      "├─Sequential: 1-3                        [-1, 32]                  --\n",
      "|    └─Linear: 2-39                      [-1, 300]                 960,300\n",
      "|    └─LeakyReLU: 2-40                   [-1, 300]                 --\n",
      "|    └─Dropout: 2-41                     [-1, 300]                 --\n",
      "|    └─Linear: 2-42                      [-1, 32]                  9,632\n",
      "|    └─Sigmoid: 2-43                     [-1, 32]                  --\n",
      "==========================================================================================\n",
      "Total params: 18,274,878\n",
      "Trainable params: 18,274,878\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (G): 15.48\n",
      "==========================================================================================\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 103.56\n",
      "Params size (MB): 69.71\n",
      "Estimated Total Size (MB): 173.84\n",
      "==========================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "├─Sequential: 1-1                        [-1, 512, 7, 7]           --\n",
       "|    └─Conv2d: 2-1                       [-1, 64, 224, 224]        1,792\n",
       "|    └─LeakyReLU: 2-2                    [-1, 64, 224, 224]        --\n",
       "|    └─Conv2d: 2-3                       [-1, 64, 224, 224]        36,928\n",
       "|    └─LeakyReLU: 2-4                    [-1, 64, 224, 224]        --\n",
       "|    └─MaxPool2d: 2-5                    [-1, 64, 112, 112]        --\n",
       "|    └─Conv2d: 2-6                       [-1, 128, 112, 112]       73,856\n",
       "|    └─LeakyReLU: 2-7                    [-1, 128, 112, 112]       --\n",
       "|    └─Conv2d: 2-8                       [-1, 128, 112, 112]       147,584\n",
       "|    └─LeakyReLU: 2-9                    [-1, 128, 112, 112]       --\n",
       "|    └─MaxPool2d: 2-10                   [-1, 128, 56, 56]         --\n",
       "|    └─Conv2d: 2-11                      [-1, 256, 56, 56]         295,168\n",
       "|    └─LeakyReLU: 2-12                   [-1, 256, 56, 56]         --\n",
       "|    └─Conv2d: 2-13                      [-1, 256, 56, 56]         590,080\n",
       "|    └─LeakyReLU: 2-14                   [-1, 256, 56, 56]         --\n",
       "|    └─Conv2d: 2-15                      [-1, 256, 56, 56]         590,080\n",
       "|    └─LeakyReLU: 2-16                   [-1, 256, 56, 56]         --\n",
       "|    └─MaxPool2d: 2-17                   [-1, 256, 28, 28]         --\n",
       "|    └─Conv2d: 2-18                      [-1, 512, 28, 28]         1,180,160\n",
       "|    └─LeakyReLU: 2-19                   [-1, 512, 28, 28]         --\n",
       "|    └─Conv2d: 2-20                      [-1, 512, 28, 28]         2,359,808\n",
       "|    └─LeakyReLU: 2-21                   [-1, 512, 28, 28]         --\n",
       "|    └─Conv2d: 2-22                      [-1, 512, 28, 28]         2,359,808\n",
       "|    └─LeakyReLU: 2-23                   [-1, 512, 28, 28]         --\n",
       "|    └─MaxPool2d: 2-24                   [-1, 512, 14, 14]         --\n",
       "|    └─Conv2d: 2-25                      [-1, 512, 14, 14]         2,359,808\n",
       "|    └─ReLU: 2-26                        [-1, 512, 14, 14]         --\n",
       "|    └─Conv2d: 2-27                      [-1, 512, 14, 14]         2,359,808\n",
       "|    └─LeakyReLU: 2-28                   [-1, 512, 14, 14]         --\n",
       "|    └─Conv2d: 2-29                      [-1, 512, 14, 14]         2,359,808\n",
       "|    └─LeakyReLU: 2-30                   [-1, 512, 14, 14]         --\n",
       "|    └─MaxPool2d: 2-31                   [-1, 512, 7, 7]           --\n",
       "├─Sequential: 1-2                        [-1, 50, 8, 8]            --\n",
       "|    └─Conv2d: 2-32                      [-1, 512, 7, 7]           2,359,808\n",
       "|    └─LeakyReLU: 2-33                   [-1, 512, 7, 7]           --\n",
       "|    └─MaxPool2d: 2-34                   [-1, 512, 3, 3]           --\n",
       "|    └─Conv2d: 2-35                      [-1, 50, 3, 3]            230,450\n",
       "|    └─LeakyReLU: 2-36                   [-1, 50, 3, 3]            --\n",
       "|    └─MaxPool2d: 2-37                   [-1, 50, 1, 1]            --\n",
       "|    └─AdaptiveAvgPool2d: 2-38           [-1, 50, 8, 8]            --\n",
       "├─Sequential: 1-3                        [-1, 32]                  --\n",
       "|    └─Linear: 2-39                      [-1, 300]                 960,300\n",
       "|    └─LeakyReLU: 2-40                   [-1, 300]                 --\n",
       "|    └─Dropout: 2-41                     [-1, 300]                 --\n",
       "|    └─Linear: 2-42                      [-1, 32]                  9,632\n",
       "|    └─Sigmoid: 2-43                     [-1, 32]                  --\n",
       "==========================================================================================\n",
       "Total params: 18,274,878\n",
       "Trainable params: 18,274,878\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 15.48\n",
       "==========================================================================================\n",
       "Input size (MB): 0.57\n",
       "Forward/backward pass size (MB): 103.56\n",
       "Params size (MB): 69.71\n",
       "Estimated Total Size (MB): 173.84\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model, torch.rand(1,3,224,224)) # May raise an error for some reason"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "580657a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the optimizer and loss_function \n",
    "\n",
    "def get_essentials():\n",
    "  loss_fun = nn.L1Loss()\n",
    "  optimizer = torch.optim.Adam(model.parameters(), lr=0.00001)\n",
    "  return loss_fun, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d50da60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining batch_train and accuracy functions\n",
    "\n",
    "\n",
    "def train_batch(data, model, loss_fun, optimizer):\n",
    "  model.train()\n",
    "  img, true_points = data\n",
    "  pred_points = model(img)\n",
    "  loss_val = loss_fun(pred_points, true_points)\n",
    "  loss_val.backward()\n",
    "  optimizer.step()\n",
    "  optimizer.zero_grad()\n",
    "  return loss_val.item()\n",
    "\n",
    "@torch.no_grad()\n",
    "def val_batch(data, model, loss_fun, optimizer):\n",
    "  model.eval()\n",
    "  img, true_points = data\n",
    "  pred_points = model(img)\n",
    "  loss_val = loss_fun(pred_points, true_points)\n",
    "  return loss_val.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7deaf937",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "loss_fun, optimizer = get_essentials()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a34af8a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                    | 0/20 [00:22<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(epochs)):\n\u001b[1;32m      6\u001b[0m   train_batch_losses, val_batch_losses \u001b[38;5;241m=\u001b[39m [], []\n\u001b[0;32m----> 7\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m train_dataloader:\n\u001b[1;32m      8\u001b[0m     train_batch_loss \u001b[38;5;241m=\u001b[39m train_batch(data, model, loss_fun, optimizer)\n\u001b[1;32m      9\u001b[0m     train_batch_losses\u001b[38;5;241m.\u001b[39mappend(train_batch_loss)\n",
      "File \u001b[0;32m~/Desktop/xxxx/Uni/Kirigami_project/Keypoint_detection_notebooks/.Keypoint_detection_notebooks/lib/python3.8/site-packages/torch/utils/data/dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    626\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    627\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 628\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    629\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    631\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    632\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/Desktop/xxxx/Uni/Kirigami_project/Keypoint_detection_notebooks/.Keypoint_detection_notebooks/lib/python3.8/site-packages/torch/utils/data/dataloader.py:671\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    669\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    670\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 671\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    672\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    673\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/Desktop/xxxx/Uni/Kirigami_project/Keypoint_detection_notebooks/.Keypoint_detection_notebooks/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:58\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     56\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     60\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/Desktop/xxxx/Uni/Kirigami_project/Keypoint_detection_notebooks/.Keypoint_detection_notebooks/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:58\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     56\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     60\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[0;32mIn[5], line 8\u001b[0m, in \u001b[0;36mImageDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[1;32m      7\u001b[0m     img_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimg_dir, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf\u001b[38;5;241m.\u001b[39miloc[idx, \u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m----> 8\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m     label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf\u001b[38;5;241m.\u001b[39miloc[idx, \u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m     10\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform_image(image)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# training and validation loops \n",
    "\n",
    "\n",
    "train_epoch, val_epoch = [], []\n",
    "for epoch in tqdm(range(epochs)):\n",
    "  train_batch_losses, val_batch_losses = [], []\n",
    "  for data in train_dataloader:\n",
    "    train_batch_loss = train_batch(data, model, loss_fun, optimizer)\n",
    "    train_batch_losses.append(train_batch_loss)\n",
    "  for data in test_dataloader:\n",
    "    val_batch_loss = val_batch(data, model, loss_fun, optimizer)\n",
    "    val_batch_losses.append(val_batch_loss)\n",
    "  train_epoch.append(np.mean(train_batch_losses))\n",
    "  val_epoch.append(np.mean(val_batch_losses))\n",
    "  \n",
    "  with open(\"output.txt\", \"a\") as f:\n",
    "    f.write(str([train_batch_loss, val_batch_loss]))\n",
    "    f.write(\"\\n\")\n",
    "\n",
    "  print(train_batch_loss, val_batch_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a2f7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), './Model_2800_VGG_Leaky_80_epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f42bd5f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(range(epochs), train_epoch, label=\"train_loss\")\n",
    "plt.plot(range(epochs), val_epoch, label=\"test_loss\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training Facial Keypoints model\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed94e046",
   "metadata": {},
   "source": [
    "# Displaying the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f7ddf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_image(img):\n",
    "    img = cv2.resize(img, (224,224))\n",
    "    img_tensor = transforms.ToTensor()(img)\n",
    "    img_mean = img_tensor.mean(dim = (1,2))\n",
    "    img_std = img_tensor.std(dim = (1,2))\n",
    "        \n",
    "    img_normalised = transforms.Normalize(img_mean, img_std)(img_tensor)\n",
    "    return img_normalised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f2974e",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = os.path.join(os.getcwd(), 'Validation/image009.jpg')\n",
    "original_img = cv2.imread(img_path)\n",
    "test_img = transform_image(original_img)\n",
    "test_img = test_img.to(device)\n",
    "\n",
    "Facial_key_points = model(test_img[None]).flatten().detach().cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c96698",
   "metadata": {},
   "outputs": [],
   "source": [
    "# index = 0\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.title(\"Image\")\n",
    "original_img = original_img[:,:,::-1]                                                              \n",
    "plt.imshow(original_img)\n",
    "plt.subplot(122)\n",
    "plt.title(\" Image with Keypoints \")\n",
    "plt.imshow(original_img)\n",
    "\n",
    "x_points = Facial_key_points.numpy()[0::2]\n",
    "y_points = Facial_key_points.numpy()[1::2]\n",
    "plt.scatter(x_points*original_img.shape[1], y_points*original_img.shape[0], s = 2)                          # scaling the keypoints with image dimension\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".Keypoint_detection_notebooks",
   "language": "python",
   "name": ".keypoint_detection_notebooks"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
