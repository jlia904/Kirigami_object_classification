{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8cbb8b46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dell/Desktop/xxxx/Uni/Kirigami_project/Keypoint_detection_notebooks/.Keypoint_detection_notebooks/lib/python3.8/site-packages/requests/__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.14) or chardet (5.1.0)/charset_normalizer (2.0.12) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "# importing relevant packages \n",
    "\n",
    "import torch \n",
    "from torchvision import models\n",
    "import pandas as pd\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn \n",
    "import glob\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt \n",
    "import torchvision.transforms as transforms\n",
    "from torchsummary import summary\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from PIL import Image\n",
    "import random\n",
    "import albumentations as A\n",
    "import glob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a2a79d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VGG_model, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.LeakyReLU(0.1,inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.LeakyReLU(0.1,inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
    "            nn.Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.LeakyReLU(0.1,inplace=True),\n",
    "            nn.Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.LeakyReLU(0.1,inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
    "            nn.Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.LeakyReLU(0.1,inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.LeakyReLU(0.1,inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.LeakyReLU(0.1,inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
    "            nn.Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.LeakyReLU(0.1,inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.LeakyReLU(0.1,inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.LeakyReLU(0.1,inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
    "            nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.LeakyReLU(0.1,inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.LeakyReLU(0.1,inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "        )\n",
    "        \n",
    "        self.avgpool = nn.Sequential(\n",
    "            nn.Conv2d(512,512, kernel_size=3, padding='same'),\n",
    "            nn.LeakyReLU(0.1,inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(512,50, kernel_size=3, padding='same'),\n",
    "            nn.LeakyReLU(0.1,inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.AdaptiveAvgPool2d(output_size=(8,8))\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(3200, 300),\n",
    "            nn.LeakyReLU(0.1,inplace=True),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(300, 32),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3daa8a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VGG_model()\n",
    "model.load_state_dict(torch.load('./Model_VGG_4_5_2000_13080_epoch'))\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d4f2ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_keypoints(img):\n",
    "    img = cv2.resize(img, (224,224))\n",
    "    img_tensor = transforms.ToTensor()(img)\n",
    "    img_mean = img_tensor.mean(dim = (1,2))\n",
    "    img_std = img_tensor.std(dim = (1,2))\n",
    "        \n",
    "    img_normalised = transforms.Normalize(img_mean, img_std)(img_tensor)\n",
    "    img_normalised = img_normalised.to(device)\n",
    "    \n",
    "    key_points = model(img_normalised[None]).flatten().detach().cpu().numpy()\n",
    "    \n",
    "    return key_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "967d6f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_keypoints(img, keypoints):                                                             \n",
    "\n",
    "    plt.imshow(img)\n",
    "\n",
    "    x_points = keypoints[0::2]\n",
    "    y_points = keypoints[1::2]\n",
    "    plt.scatter(x_points*img.shape[1], y_points*img.shape[0], s = 4, c=(1,0,0))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "337c9168",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_names = ['Grasp_dataset_cylinder_20', 'Grasp_dataset_cylinder_40', 'Grasp_dataset_cylinder_60', 'Grasp_dataset_square_20', 'Grasp_dataset_square_40', 'Grasp_dataset_square_60']\n",
    "header = ['pressure_reading_1', 'pressure_reading_2', 'p1_x', 'p1_y', 'p2_x', 'p2_y', 'p3_x', 'p3_y', 'p4_x', 'p4_y', 'p5_x', 'p5_y', 'p6_x', 'p6_y', 'p7_x', 'p7_y', 'p8_x', 'p8_y', 'p9_x', 'p9_y', 'p10_x', 'p10_y', 'p11_x', 'p11_y', 'p12_x', 'p12_y', 'p13_x', 'p13_y', 'p14_x', 'p14_y', 'p15_x', 'p15_y', 'p16_x', 'p16_y', 'label']\n",
    "\n",
    "current_dir = os. getcwd()\n",
    "\n",
    "pressure_reading_1_arr = []\n",
    "pressure_reading_2_arr = []\n",
    "p1_x_arr = []\n",
    "p1_y_arr = []\n",
    "p2_x_arr = []\n",
    "p2_y_arr = []\n",
    "p3_x_arr = []\n",
    "p3_y_arr = []\n",
    "p4_x_arr = []\n",
    "p4_y_arr = []\n",
    "p5_x_arr = []\n",
    "p5_y_arr = []\n",
    "p6_x_arr = []\n",
    "p6_y_arr = []\n",
    "p7_x_arr = []\n",
    "p7_y_arr = []\n",
    "p8_x_arr = []\n",
    "p8_y_arr = []\n",
    "p9_x_arr = []\n",
    "p9_y_arr = []\n",
    "p10_x_arr = []\n",
    "p10_y_arr = []\n",
    "p11_x_arr = []\n",
    "p11_y_arr = []\n",
    "p12_x_arr = []\n",
    "p12_y_arr = []\n",
    "p13_x_arr = []\n",
    "p13_y_arr = []\n",
    "p14_x_arr = []\n",
    "p14_y_arr = []\n",
    "p15_x_arr = []\n",
    "p15_y_arr = []\n",
    "p16_x_arr = []\n",
    "p16_y_arr = []\n",
    "label_arr = []\n",
    "\n",
    "\n",
    "for f in dataset_names:\n",
    "    \n",
    "    image_dir = os.path.join(current_dir + '/Grasp_dataset', f)\n",
    "    data_dir = os.path.join(image_dir, f + '.csv')\n",
    "    df = pd.read_csv(data_dir)\n",
    "    pressure_reading_1_arr = np.concatenate((pressure_reading_1_arr, df['pressure_reading_1'].values))\n",
    "    pressure_reading_2_arr = np.concatenate((pressure_reading_2_arr, df['pressure_reading_2'].values))\n",
    "    label_arr = np.concatenate((label_arr, df['label'].values))\n",
    "    \n",
    "    j = 0\n",
    "    \n",
    "    while j < df.shape[0]:\n",
    "        image = cv2.imread(os.path.join(image_dir, df.iloc[j]['image_name']))\n",
    "        keypoints = predict_keypoints(image)\n",
    "        \n",
    "#         if j == 20:\n",
    "#             plot_keypoints(image, keypoints)\n",
    "        \n",
    "        p1_x_arr.append(keypoints[0])\n",
    "        p1_y_arr.append(keypoints[1])\n",
    "        p2_x_arr.append(keypoints[2])\n",
    "        p2_y_arr.append(keypoints[3])\n",
    "        p3_x_arr.append(keypoints[4])\n",
    "        p3_y_arr.append(keypoints[5])\n",
    "        p4_x_arr.append(keypoints[6])\n",
    "        p4_y_arr.append(keypoints[7])\n",
    "        p5_x_arr.append(keypoints[8])\n",
    "        p5_y_arr.append(keypoints[9])\n",
    "        p6_x_arr.append(keypoints[10])\n",
    "        p6_y_arr.append(keypoints[11])\n",
    "        p7_x_arr.append(keypoints[12])\n",
    "        p7_y_arr.append(keypoints[13])\n",
    "        p8_x_arr.append(keypoints[14])\n",
    "        p8_y_arr.append(keypoints[15])\n",
    "        p9_x_arr.append(keypoints[16])\n",
    "        p9_y_arr.append(keypoints[17])\n",
    "        p10_x_arr.append(keypoints[18])\n",
    "        p10_y_arr.append(keypoints[19])\n",
    "        p11_x_arr.append(keypoints[20])\n",
    "        p11_y_arr.append(keypoints[21])\n",
    "        p12_x_arr.append(keypoints[22])\n",
    "        p12_y_arr.append(keypoints[23])\n",
    "        p13_x_arr.append(keypoints[24])\n",
    "        p13_y_arr.append(keypoints[25])\n",
    "        p14_x_arr.append(keypoints[26])\n",
    "        p14_y_arr.append(keypoints[27])\n",
    "        p15_x_arr.append(keypoints[28])\n",
    "        p15_y_arr.append(keypoints[29])\n",
    "        p16_x_arr.append(keypoints[30])\n",
    "        p16_y_arr.append(keypoints[31])\n",
    "        \n",
    "        j = j + 1\n",
    "        \n",
    "    \n",
    "grasp_dataset = pd.concat([pd.Series(pressure_reading_1_arr), pd.Series(pressure_reading_2_arr), pd.Series(p1_x_arr), pd.Series(p1_y_arr), pd.Series(p2_x_arr), pd.Series(p2_y_arr), pd.Series(p3_x_arr), pd.Series(p3_y_arr), pd.Series(p4_x_arr), pd.Series(p4_y_arr), pd.Series(p5_x_arr), pd.Series(p5_y_arr), pd.Series(p6_x_arr), pd.Series(p6_y_arr), pd.Series(p7_x_arr), pd.Series(p7_y_arr), pd.Series(p8_x_arr), pd.Series(p8_y_arr), pd.Series(p9_x_arr), pd.Series(p9_y_arr), pd.Series(p10_x_arr), pd.Series(p10_y_arr), pd.Series(p11_x_arr), pd.Series(p11_y_arr), pd.Series(p12_x_arr), pd.Series(p12_y_arr), pd.Series(p13_x_arr), pd.Series(p13_y_arr), pd.Series(p14_x_arr), pd.Series(p14_y_arr), pd.Series(p15_x_arr), pd.Series(p15_y_arr), pd.Series(p16_x_arr), pd.Series(p16_y_arr), pd.Series(label_arr)], axis=1, keys=header)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b90e6ca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   pressure_reading_1  pressure_reading_2      p1_x      p1_y      p2_x  \\\n",
      "0                2.34                0.60  0.118427  0.308181  0.466023   \n",
      "1               11.33                8.38  0.125501  0.302882  0.467878   \n",
      "\n",
      "       p2_y      p3_x      p3_y      p4_x      p4_y  ...     p12_y     p13_x  \\\n",
      "0  0.105639  0.813544  0.293256  0.812743  0.639847  ...  0.762908  0.517871   \n",
      "1  0.105955  0.815525  0.295242  0.813233  0.639469  ...  0.762234  0.518357   \n",
      "\n",
      "      p13_y     p14_x     p14_y     p15_x     p15_y     p16_x     p16_y  \\\n",
      "0  0.624431  0.523356  0.495080  0.513363  0.359326  0.498104  0.213229   \n",
      "1  0.624096  0.522916  0.494591  0.512777  0.358391  0.497956  0.211643   \n",
      "\n",
      "         label  \n",
      "0  cylinder_20  \n",
      "1  cylinder_20  \n",
      "\n",
      "[2 rows x 35 columns]\n"
     ]
    }
   ],
   "source": [
    "print(grasp_dataset.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8afcd06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   pressure_reading_1  pressure_reading_2      p1_x      p1_y      p2_x  \\\n",
      "0                2.34                0.60  0.118427  0.308181  0.466023   \n",
      "1               11.33                8.38  0.125501  0.302882  0.467878   \n",
      "\n",
      "       p2_y      p3_x      p3_y      p4_x      p4_y  ...     p12_x     p12_y  \\\n",
      "0  0.105639  0.813544  0.293256  0.812743  0.639847  ...  0.511521  0.762908   \n",
      "1  0.105955  0.815525  0.295242  0.813233  0.639469  ...  0.514578  0.762234   \n",
      "\n",
      "      p13_x     p13_y     p14_x     p14_y     p15_x     p15_y     p16_x  \\\n",
      "0  0.517871  0.624431  0.523356  0.495080  0.513363  0.359326  0.498104   \n",
      "1  0.518357  0.624096  0.522916  0.494591  0.512777  0.358391  0.497956   \n",
      "\n",
      "      p16_y  \n",
      "0  0.213229  \n",
      "1  0.211643  \n",
      "\n",
      "[2 rows x 34 columns]\n",
      "0    cylinder_20\n",
      "1    cylinder_20\n",
      "Name: label, dtype: object\n"
     ]
    }
   ],
   "source": [
    "grasp_data = grasp_dataset.drop(columns=[\"label\"], axis=1)\n",
    "grasp_label = grasp_dataset['label']\n",
    "\n",
    "print(grasp_data.head(2))\n",
    "print(grasp_label.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d6aa8700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation results: [1.         0.875      0.91666667 0.875      0.91666667 1.\n",
      " 0.95833333 0.95833333 0.875      0.875     ]\n",
      "Average accuracy: 0.925\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(grasp_data, grasp_label, test_size=0.2, random_state=np.random.randint(100))\n",
    "\n",
    "# print(X_train.head(3))\n",
    "\n",
    "# knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# knn.fit(X_train, y_train)\n",
    "\n",
    "# y_pred = knn.predict(X_test)\n",
    "\n",
    "# accuracy = knn.score(X_test, y_test)\n",
    "# print('Accuracy:', accuracy)\n",
    "\n",
    "# clf = RandomForestClassifier(n_estimators=1000, max_depth=100, random_state=np.random.randint(100))\n",
    "# clf2 = HistGradientBoostingClassifier(max_iter=200, random_state=np.random.randint(100))\n",
    "# clf3 = GradientBoostingClassifier(n_estimators=200, learning_rate=0.1, max_depth=1, random_state=0).fit(X_train, y_train)\n",
    "# clf = VotingClassifier(estimators=[('lr', clf1), ('rf', clf2), ('gnb', clf3)],voting='hard')\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=1000, max_depth=100, random_state=np.random.randint(100))\n",
    "num_folds = 10\n",
    "cv_method = KFold(n_splits=num_folds, shuffle=True, random_state=np.random.randint(100))\n",
    "cv_results = cross_val_score(clf, grasp_data, grasp_label, cv=cv_method, scoring='accuracy')\n",
    "\n",
    "print('Cross-validation results:', cv_results)\n",
    "print('Average accuracy:', cv_results.mean())\n",
    "\n",
    "# clf.fit(X_train, y_train)\n",
    "\n",
    "# accuracy = clf.score(X_test, y_test)\n",
    "# print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9281437",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9982fb40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f1bc14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d25dca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3427cdab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e672ddbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84543cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".Keypoint_detection_notebooks",
   "language": "python",
   "name": ".keypoint_detection_notebooks"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
