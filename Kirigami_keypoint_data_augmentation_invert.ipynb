{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cbb8b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing relevant packages \n",
    "\n",
    "import torch \n",
    "from torchvision import models\n",
    "import pandas as pd\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn \n",
    "import glob\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt \n",
    "import torchvision.transforms as transforms\n",
    "from torchsummary import summary\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from PIL import Image\n",
    "import random\n",
    "import albumentations as A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205c2408",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a57444",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to visualize keypoints on an image\n",
    "\n",
    "KEYPOINT_COLOR = (0, 255, 0) # Green\n",
    "\n",
    "def vis_keypoints(image, keypoints, color=KEYPOINT_COLOR, diameter=15):\n",
    "    image = image.copy()\n",
    "\n",
    "    for (x, y) in keypoints:\n",
    "        cv2.circle(image, (int(x), int(y)), diameter, (0, 255, 0), -1)\n",
    "        \n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad986751",
   "metadata": {},
   "outputs": [],
   "source": [
    "# original_images_df_dir = os.path.join(os. getcwd(), 'Kirigami_dataset_1')\n",
    "# original_images_df_dir = os.path.join(os. getcwd(), 'Kirigami_dataset_2')\n",
    "# original_images_df_dir = os.path.join(os. getcwd(), 'Kirigami_dataset_3')\n",
    "# original_images_df_dir = os.path.join(os. getcwd(), 'Kirigami_dataset_4')\n",
    "# original_images_df_dir = os.path.join(os. getcwd(), 'Kirigami_dataset_5')\n",
    "# original_images_df_dir = os.path.join(os. getcwd(), 'Kirigami_dataset_6')\n",
    "original_images_df_dir = os.path.join(os. getcwd(), 'Kirigami_dataset_7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3379cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# original_df = pd.read_csv('./Kirigami_dataset_1/original_kirigami_image_df.csv')\n",
    "# original_df = pd.read_csv('./Kirigami_dataset_2/Kirigami_dataset_2.csv')\n",
    "# original_df = pd.read_csv('./Kirigami_dataset_3/Kirigami_dataset_3.csv')\n",
    "# original_df = pd.read_csv('./Kirigami_dataset_4/Kirigami_dataset_4.csv')\n",
    "# original_df = pd.read_csv('./Kirigami_dataset_5/Kirigami_dataset_5.csv')\n",
    "# original_df = pd.read_csv('./Kirigami_dataset_6/Kirigami_dataset_6.csv')\n",
    "original_df = pd.read_csv('./Kirigami_dataset_7/Kirigami_dataset_7.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89898199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_images_dir = os.path.join(os. getcwd(), 'Kirigami_dataset_invert')\n",
    "# new_images_dir = os.path.join(os. getcwd(), 'Kirigami_dataset_2_invert')\n",
    "# new_images_dir = os.path.join(os. getcwd(), 'Kirigami_dataset_3_invert')\n",
    "# new_images_dir = os.path.join(os. getcwd(), 'Kirigami_dataset_4_invert')\n",
    "# new_images_dir = os.path.join(os. getcwd(), 'Kirigami_dataset_5_invert')\n",
    "# new_images_dir = os.path.join(os. getcwd(), 'Kirigami_dataset_6_invert')\n",
    "new_images_dir = os.path.join(os. getcwd(), 'Kirigami_dataset_7_invert')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75678566",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "header = ['image_name', 'p1_x', 'p1_y', 'p2_x', 'p2_y', 'p3_x', 'p3_y', 'p4_x', 'p4_y', 'p5_x', 'p5_y', 'p6_x', 'p6_y', 'p7_x', 'p7_y', 'p8_x', 'p8_y', 'p9_x', 'p9_y', 'p10_x', 'p10_y', 'p11_x', 'p11_y', 'p12_x', 'p12_y', 'p13_x', 'p13_y', 'p14_x', 'p14_y', 'p15_x', 'p15_y', 'p16_x', 'p16_y']\n",
    "new_images_df = pd.DataFrame(columns=header)\n",
    "\n",
    "i = 0\n",
    "repeat = 0\n",
    "\n",
    "while i < original_df.shape[0]:\n",
    "    \n",
    "    transform = A.Compose([\n",
    "        A.Affine(rotate=180, p=1)\n",
    "    ], keypoint_params=A.KeypointParams(format='xy'))\n",
    "    \n",
    "    \n",
    "    image_to_be_transformed = cv2.imread(os.path.join(original_images_df_dir, original_df.iloc[i]['image_name']))\n",
    "    \n",
    "    x_points = original_df.iloc[i][1:][::2]*image_to_be_transformed.shape[1]\n",
    "    y_points = original_df.iloc[i][2:][::2]*image_to_be_transformed.shape[0]\n",
    "    albumentations_keypoints = list(zip(x_points,y_points))\n",
    "    \n",
    "#     vis_keypoints(image_to_be_transformed, albumentations_keypoints, color=KEYPOINT_COLOR, diameter=15)\n",
    "    \n",
    "    transformed = transform(image=image_to_be_transformed, keypoints=albumentations_keypoints)\n",
    "    transformed_image = transformed['image']\n",
    "    transformed_keypoints = transformed['keypoints']\n",
    "    \n",
    "    rearranged_transformed_keypoints = [(0,0) for _ in range(16)]\n",
    "    rearranged_transformed_keypoints[0] = transformed_keypoints[3]#1->4\n",
    "    rearranged_transformed_keypoints[1] = transformed_keypoints[4]#2->5\n",
    "    rearranged_transformed_keypoints[2] = transformed_keypoints[5]#3->6\n",
    "    rearranged_transformed_keypoints[3] = transformed_keypoints[0]#4->1\n",
    "    rearranged_transformed_keypoints[4] = transformed_keypoints[1]#5->2\n",
    "    rearranged_transformed_keypoints[5] = transformed_keypoints[2]#6->3\n",
    "    rearranged_transformed_keypoints[6] = transformed_keypoints[11]#7->12\n",
    "    rearranged_transformed_keypoints[7] = transformed_keypoints[12]#8->13\n",
    "    rearranged_transformed_keypoints[8] = transformed_keypoints[13]#9->14\n",
    "    rearranged_transformed_keypoints[9] = transformed_keypoints[14]#10->15\n",
    "    rearranged_transformed_keypoints[10] = transformed_keypoints[15]#11->16\n",
    "    rearranged_transformed_keypoints[11] = transformed_keypoints[6]#12->7\n",
    "    rearranged_transformed_keypoints[12] = transformed_keypoints[7]#13->8\n",
    "    rearranged_transformed_keypoints[13] = transformed_keypoints[8]#14->9\n",
    "    rearranged_transformed_keypoints[14] = transformed_keypoints[9]#15->10\n",
    "    rearranged_transformed_keypoints[15] = transformed_keypoints[10]#16->11\n",
    "    \n",
    "#     vis_keypoints(transformed_image, transformed_keypoints, color=KEYPOINT_COLOR, diameter=15)\n",
    "    \n",
    "    if repeat >= 20:\n",
    "        repeat = 0\n",
    "        i = i + 1\n",
    "        continue\n",
    "    \n",
    "    if len(transformed_keypoints) != 16:\n",
    "        print(original_df.iloc[i]['image_name'])\n",
    "        repeat = repeat + 1\n",
    "        \n",
    "        continue\n",
    "    \n",
    "    new_image_name = 'I' + original_df.iloc[i]['image_name']\n",
    "    \n",
    "    new_images_df.loc[len(new_images_df)] = new_image_name\n",
    "    \n",
    "    flatten_coordinates = np.array(rearranged_transformed_keypoints).flatten()  \n",
    "    flatten_coordinates[::2] = [x / transformed_image.shape[1] for x in flatten_coordinates[::2]]\n",
    "    flatten_coordinates[1::2] = [x / transformed_image.shape[0] for x in flatten_coordinates[1::2]]\n",
    "    \n",
    "    new_images_df.iloc[len(new_images_df)-1, 1:33] = flatten_coordinates\n",
    "    \n",
    "    transformed_image[..., [0, 2]] = transformed_image[..., [2, 0]]\n",
    "    img = Image.fromarray(np.uint8(transformed_image))\n",
    "    img.save(os.path.join(new_images_dir, new_image_name))\n",
    "    \n",
    "    repeat = 0\n",
    "    i = i + 1\n",
    "    \n",
    "    \n",
    "new_images_df.to_csv(os.path.join(new_images_dir, 'Kirigami_dataset_7_invert.csv'), index=False)\n",
    "\n",
    "print(\"Finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242e6e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(new_images_df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db81ed4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = os. getcwd()\n",
    "images_dir = os.path.join(current_dir, 'Kirigami_dataset_7_invert')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25cb052d",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_idx = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da77edd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_images_df.iloc[img_idx]['image_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde35fb3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img_arr = cv2.imread(os.path.join(images_dir, new_images_df.iloc[img_idx]['image_name']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16cdbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158f31cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(img_arr)\n",
    "x_points = new_images_df.iloc[img_idx][1:7][::2]\n",
    "y_points = new_images_df.iloc[img_idx][2:8][::2]\n",
    "x_width = img_arr.shape[1]\n",
    "y_height = img_arr.shape[0]\n",
    "\n",
    "plt.scatter(x_points*x_width, y_points*y_height)\n",
    "# plt.scatter(x_points, y_points)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".Keypoint_detection_notebooks",
   "language": "python",
   "name": ".keypoint_detection_notebooks"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
