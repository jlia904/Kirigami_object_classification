{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cbb8b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing relevant packages \n",
    "\n",
    "import torch \n",
    "from torchvision import models\n",
    "import pandas as pd\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "import glob\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt \n",
    "import torchvision.transforms as transforms\n",
    "from torchsummary import summary\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from PIL import Image\n",
    "import random\n",
    "import albumentations as A\n",
    "import glob\n",
    "from shapely.geometry import Polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31d09c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>div.output_scroll { height: 45em; }</style>\"))\n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2a79d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VGG_model, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.LeakyReLU(0.1,inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.LeakyReLU(0.1,inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
    "            nn.Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.LeakyReLU(0.1,inplace=True),\n",
    "            nn.Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.LeakyReLU(0.1,inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
    "            nn.Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.LeakyReLU(0.1,inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.LeakyReLU(0.1,inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.LeakyReLU(0.1,inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
    "            nn.Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.LeakyReLU(0.1,inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.LeakyReLU(0.1,inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.LeakyReLU(0.1,inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
    "            nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.LeakyReLU(0.1,inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.LeakyReLU(0.1,inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "        )\n",
    "        \n",
    "        self.avgpool = nn.Sequential(\n",
    "            nn.Conv2d(512,512, kernel_size=3, padding='same'),\n",
    "            nn.LeakyReLU(0.1,inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(512,50, kernel_size=3, padding='same'),\n",
    "            nn.LeakyReLU(0.1,inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.AdaptiveAvgPool2d(output_size=(8,8))\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(3200, 300),\n",
    "            nn.LeakyReLU(0.1,inplace=True),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(300, 32),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3daa8a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = VGG_model()\n",
    "model.load_state_dict(torch.load('./Model_VGG_4_5_2000_13080_epoch'))\n",
    "model = model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4f2ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_keypoints(img):\n",
    "    img = cv2.resize(img, (224,224))\n",
    "    img_tensor = transforms.ToTensor()(img)\n",
    "    img_mean = img_tensor.mean(dim = (1,2))\n",
    "    img_std = img_tensor.std(dim = (1,2))\n",
    "        \n",
    "    img_normalised = transforms.Normalize(img_mean, img_std)(img_tensor)\n",
    "    img_normalised = img_normalised.to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        key_points = model(img_normalised[None]).flatten().detach().cpu().numpy()\n",
    "    \n",
    "    return key_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967d6f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_keypoints(img, keypoints):                                                             \n",
    "\n",
    "    plt.imshow(img)\n",
    "\n",
    "    keypoints = np.array(keypoints)\n",
    "    \n",
    "    x_points = keypoints[0::2]\n",
    "    y_points = keypoints[1::2]\n",
    "    \n",
    "    plt.scatter(x_points*img.shape[1], y_points*img.shape[0], s = 4, c=(1,0,0))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b342db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_num(x):\n",
    "    return x*random.uniform(0.95, 1.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5721aaf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_label(x):\n",
    "    string_to_int_dict = {'orange':0, 'pear':1, 'banana':2, 'plum':3, 'egg':4, 'strawberry':5, 'chicken':6, 'bayberry':7, 'redgrape':8, 'pistachio':9}\n",
    "    return string_to_int_dict[x]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a18f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_image(img):\n",
    "    img = cv2.resize(img, (224,224))\n",
    "    img_tensor = transforms.ToTensor()(img)\n",
    "    img_mean = img_tensor.mean(dim = (1,2))\n",
    "    img_std = img_tensor.std(dim = (1,2))\n",
    "        \n",
    "    img_normalised = transforms.Normalize(img_mean, img_std)(img_tensor)\n",
    "    return img_normalised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29100f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_data():\n",
    "\n",
    "    source_folder = os.path.join(os. getcwd(), 'Grasp_dataset_validation')\n",
    "#     destination_folder = os.path.join(os. getcwd(), 'Grasp_dataset_augmented')\n",
    "    dataset_names = ['Grasp_dataset_orange', 'Grasp_dataset_pear', 'Grasp_dataset_banana', 'Grasp_dataset_plum', 'Grasp_dataset_egg', 'Grasp_dataset_strawberry', 'Grasp_dataset_chicken', 'Grasp_dataset_bayberry', 'Grasp_dataset_redgrape', 'Grasp_dataset_pistachio']\n",
    "    \n",
    "    complete_df_set = pd.DataFrame()\n",
    "    first_dataset = True\n",
    "    \n",
    "    for f in dataset_names:\n",
    "        \n",
    "        df = pd.read_csv(source_folder + '/' + f + '/' + f + '.csv')\n",
    "        \n",
    "#         num_cols = df.select_dtypes(include=['float']).columns\n",
    "#         df[num_cols] = df[num_cols].applymap(process_num)\n",
    "        df['label'] = df['label'].apply(process_label)\n",
    "        \n",
    "        i = 0\n",
    "#         repeat = 0\n",
    "        \n",
    "        header = ['p1_x', 'p1_y', 'p2_x', 'p2_y', 'p3_x', 'p3_y', 'p4_x', 'p4_y', 'p5_x', 'p5_y', 'p6_x', 'p6_y',\n",
    "              'p7_x', 'p7_y', 'p8_x', 'p8_y', 'p9_x', 'p9_y', 'p10_x', 'p10_y', 'p11_x', 'p11_y', 'p12_x', 'p12_y', 'p13_x',\n",
    "              'p13_y', 'p14_x', 'p14_y', 'p15_x', 'p15_y', 'p16_x', 'p16_y']\n",
    "            \n",
    "        keypoints_df = pd.DataFrame(columns=header)\n",
    "        \n",
    "        while i < df.shape[0]:\n",
    "        \n",
    "#             transform = A.Compose([\n",
    "#                     A.Affine(rotate=random.uniform(-1, 1), p=1),\n",
    "#                     A.Affine(translate_percent={'x': random.uniform(-0.02, 0.02), 'y': random.uniform(-0.02, 0.02)}, p=1),\n",
    "#                     A.Affine(shear={'x': random.uniform(-1, 1), 'y': random.uniform(-0.5, 0.5)}, p=1),\n",
    "#                     A.Affine(scale=(0.98, 1.01), p=1)\n",
    "#                 ], keypoint_params=A.KeypointParams(format='xy'))\n",
    "            \n",
    "            image_to_be_transformed = cv2.imread(os.path.join(source_folder + '/' + f, df.iloc[i]['image_name']))\n",
    "            \n",
    "            processed_image_to_be_transformed = transform_image(image_to_be_transformed)\n",
    "            processed_image_to_be_transformed = processed_image_to_be_transformed.to(device)\n",
    "\n",
    "            keypoints = model(processed_image_to_be_transformed[None]).flatten().detach().cpu().numpy()\n",
    "            \n",
    "#             x_points = keypoints[0::2]\n",
    "#             y_points = keypoints[1::2]\n",
    "#             x_points = x_points*image_to_be_transformed.shape[1]\n",
    "#             y_points = y_points*image_to_be_transformed.shape[0]\n",
    "\n",
    "#             transformed = transform(image=image_to_be_transformed, keypoints=list(zip(x_points, y_points)))\n",
    "#             transformed_image = transformed['image']\n",
    "#             transformed_keypoints = transformed['keypoints']\n",
    "            \n",
    "#             if repeat >= 20:\n",
    "#                 print('skipping')\n",
    "#                 repeat = 0\n",
    "#                 i = i + 1\n",
    "#                 continue\n",
    "    \n",
    "#             if len(transformed_keypoints) != 16:\n",
    "# #                 print(df.iloc[i]['image_name'])\n",
    "#                 repeat = repeat + 1\n",
    "#                 continue\n",
    "            \n",
    "#             flatten_coordinates = np.array(transformed_keypoints).flatten()\n",
    "#             flatten_coordinates[::2] = [x / transformed_image.shape[1] for x in flatten_coordinates[::2]]\n",
    "#             flatten_coordinates[1::2] = [x / transformed_image.shape[0] for x in flatten_coordinates[1::2]]\n",
    "#             keypoints_df.loc[len(keypoints_df)] = pd.Series(flatten_coordinates, index=header)\n",
    "            keypoints_df.loc[len(keypoints_df)] = pd.Series(keypoints, index=header)\n",
    "#             print(flatten_coordinates)\n",
    "#             print(keypoints_df)\n",
    "            \n",
    "#             transformed_image[..., [0, 2]] = transformed_image[..., [2, 0]]\n",
    "#             img = Image.fromarray(np.uint8(transformed_image))\n",
    "##             img.save(destination_folder + '/' + f + '/' + df.iloc[i]['image_name'])\n",
    "            \n",
    "#             plot_keypoints(transformed_image, flatten_coordinates)\n",
    "            \n",
    "#             repeat = 0\n",
    "            i = i + 1\n",
    "        \n",
    "        \n",
    "        complete_df = pd.concat([df, keypoints_df], axis=1)\n",
    "        \n",
    "        if first_dataset == True:\n",
    "            complete_df_set = complete_df\n",
    "            first_dataset = False\n",
    "        else:\n",
    "            complete_df_set = pd.concat([complete_df_set, complete_df], axis=0)\n",
    "    \n",
    "    return complete_df_set\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e745dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "grasp_dataset = augment_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4c83dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "grasp_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a17793",
   "metadata": {},
   "outputs": [],
   "source": [
    "grasp_dataset.to_csv(os. getcwd() + '/Grasp_dataset_validation/Grasp_dataset_validation.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed893c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = cv2.imread('/home/dell/Desktop/xxxx/Uni/Kirigami_project/Keypoint_detection_notebooks/Grasp_dataset_validation/Grasp_dataset_orange/Gimage01.jpg')\n",
    "# test_keypoints = [0.106263,0.337210,0.477025,0.024124,0.842651,0.300729,0.854075,0.668821,0.490920,0.961230,0.118611,0.717911,0.434433,0.214938,0.409409,0.380412,0.400345,0.517087,0.415228,0.649297,0.446195,0.798699,0.530012,0.806445,0.552811,0.648003,0.562197,0.517421,0.547592,0.382726,0.520092,0.223248]\n",
    "# test_keypoints = [0.106450,0.338342,0.477561,0.022447,0.846903,0.293336,0.856888,0.671597,0.491889,0.963116,0.117257,0.718756,0.435700,0.213296,0.411332,0.379326,0.402074,0.516793,0.416912,0.650254,0.447601,0.800403,0.531560,0.807078,0.555508,0.648352,0.565423,0.516975,0.551047,0.381894,0.522536,0.221846]\n",
    "# test_keypoints = [0.104051,0.385883,0.449236,0.029271,0.766694,0.166392,0.810244,0.753678,0.465028,0.984781,0.116524,0.688441,0.425988,0.217917,0.408998,0.387639,0.401467,0.527196,0.414431,0.660729,0.437452,0.813847,0.509109,0.811115,0.536722,0.652908,0.546594,0.525347,0.532540,0.391883,0.500237,0.232379]\n",
    "# test_keypoints = [0.103694,0.385875,0.450026,0.032703,0.765393,0.165926,0.813854,0.756306,0.466416,0.982563,0.114526,0.689697,0.424660,0.218869,0.407868,0.387329,0.401262,0.525269,0.414385,0.658711,0.436980,0.812236,0.510767,0.809579,0.535420,0.653263,0.543789,0.524308,0.531166,0.390567,0.501586,0.236101]\n",
    "# test_keypoints = [0.100689,0.335815,0.457177,0.010830,0.800411,0.238211,0.830682,0.678452,0.473252,0.951701,0.112468,0.706506,0.420512,0.206316,0.397928,0.375180,0.390573,0.512799,0.405409,0.644206,0.434197,0.792113,0.509854,0.798087,0.531411,0.641818,0.540527,0.512747,0.526884,0.377140,0.500154,0.214908]\n",
    "test_keypoints = [0.100949,0.336677,0.457870,0.010349,0.801521,0.236692,0.835202,0.680884,0.474621,0.953460,0.111878,0.706665,0.421195,0.207399,0.398815,0.376122,0.390492,0.513999,0.405396,0.645739,0.435172,0.792251,0.512398,0.798200,0.535553,0.642897,0.544832,0.513761,0.530908,0.377717,0.503296,0.214640]\n",
    "print(len(test_keypoints))\n",
    "plot_keypoints(test_image, test_keypoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5530acc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e235c848",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".Keypoint_detection_notebooks",
   "language": "python",
   "name": ".keypoint_detection_notebooks"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
