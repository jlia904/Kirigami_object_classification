{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cbb8b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing relevant packages \n",
    "\n",
    "import torch \n",
    "from torchvision import models\n",
    "import pandas as pd\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "import glob\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt \n",
    "import torchvision.transforms as transforms\n",
    "from torchsummary import summary\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from PIL import Image\n",
    "import random\n",
    "import albumentations as A\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31d09c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>div.output_scroll { height: 45em; }</style>\"))\n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2a79d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VGG_model, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.LeakyReLU(0.1,inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.LeakyReLU(0.1,inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
    "            nn.Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.LeakyReLU(0.1,inplace=True),\n",
    "            nn.Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.LeakyReLU(0.1,inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
    "            nn.Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.LeakyReLU(0.1,inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.LeakyReLU(0.1,inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.LeakyReLU(0.1,inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
    "            nn.Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.LeakyReLU(0.1,inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.LeakyReLU(0.1,inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.LeakyReLU(0.1,inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
    "            nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.LeakyReLU(0.1,inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.LeakyReLU(0.1,inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "        )\n",
    "        \n",
    "        self.avgpool = nn.Sequential(\n",
    "            nn.Conv2d(512,512, kernel_size=3, padding='same'),\n",
    "            nn.LeakyReLU(0.1,inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(512,50, kernel_size=3, padding='same'),\n",
    "            nn.LeakyReLU(0.1,inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.AdaptiveAvgPool2d(output_size=(8,8))\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(3200, 300),\n",
    "            nn.LeakyReLU(0.1,inplace=True),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(300, 32),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3daa8a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = VGG_model()\n",
    "model.load_state_dict(torch.load('./Model_VGG_7_1000_22100_epoch'))\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4f2ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_keypoints(img):\n",
    "    img = cv2.resize(img, (224,224))\n",
    "    img_tensor = transforms.ToTensor()(img)\n",
    "    img_mean = img_tensor.mean(dim = (1,2))\n",
    "    img_std = img_tensor.std(dim = (1,2))\n",
    "        \n",
    "    img_normalised = transforms.Normalize(img_mean, img_std)(img_tensor)\n",
    "    img_normalised = img_normalised.to(device)\n",
    "    \n",
    "    key_points = model(img_normalised[None]).flatten().detach().cpu().numpy()\n",
    "    \n",
    "    return key_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967d6f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_keypoints(img, keypoints):                                                             \n",
    "\n",
    "    plt.imshow(img)\n",
    "\n",
    "    keypoints = np.array(keypoints)\n",
    "    \n",
    "    x_points = keypoints[0::2]\n",
    "    y_points = keypoints[1::2]\n",
    "    \n",
    "    plt.scatter(x_points*img.shape[1], y_points*img.shape[0], s = 4, c=(1,0,0))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b342db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_num(x):\n",
    "    return x*random.uniform(0.99, 1.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5721aaf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_label(x):\n",
    "    string_to_int_dict = {'orange':0, 'pear':1, 'banana':2, 'plum':3, 'egg':4, 'strawberry':5, 'chicken':6, 'bayberry':7, 'redgrape':8, 'pistachio':9}\n",
    "    return string_to_int_dict[x]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a18f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_image(img):\n",
    "    img = cv2.resize(img, (224,224))\n",
    "    img_tensor = transforms.ToTensor()(img)\n",
    "    img_mean = img_tensor.mean(dim = (1,2))\n",
    "    img_std = img_tensor.std(dim = (1,2))\n",
    "        \n",
    "    img_normalised = transforms.Normalize(img_mean, img_std)(img_tensor)\n",
    "    return img_normalised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29100f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_data():\n",
    "\n",
    "    source_folder = os.path.join(os. getcwd(), 'Grasp_dataset_2')\n",
    "    destination_folder = os.path.join(os. getcwd(), 'Grasp_dataset_augmented')\n",
    "    dataset_names = ['Grasp_dataset_orange', 'Grasp_dataset_pear', 'Grasp_dataset_banana', 'Grasp_dataset_plum', 'Grasp_dataset_egg', 'Grasp_dataset_strawberry', 'Grasp_dataset_chicken', 'Grasp_dataset_bayberry', 'Grasp_dataset_redgrape', 'Grasp_dataset_pistachio']\n",
    "\n",
    "    for f in dataset_names:\n",
    "        \n",
    "        files = glob.glob(destination_folder + '/' + f + '/*')\n",
    "        \n",
    "        for file in files:\n",
    "            os.remove(file)\n",
    "        \n",
    "        df = pd.read_csv(source_folder + '/' + f + '/' + f + '.csv')\n",
    "        \n",
    "        num_cols = df.select_dtypes(include=['float']).columns\n",
    "        df[num_cols] = df[num_cols].applymap(process_num)\n",
    "        df['label'] = df['label'].apply(process_label)\n",
    "        \n",
    "#         df.to_csv(destination_folder + '/' + f + '/' + f + '.csv', index=False)\n",
    "        \n",
    "        i = 0\n",
    "        repeat = 0\n",
    "        \n",
    "        header = ['p1_x', 'p1_y', 'p2_x', 'p2_y', 'p3_x', 'p3_y', 'p4_x', 'p4_y', 'p5_x', 'p5_y', 'p6_x', 'p6_y',\n",
    "              'p7_x', 'p7_y', 'p8_x', 'p8_y', 'p9_x', 'p9_y', 'p10_x', 'p10_y', 'p11_x', 'p11_y', 'p12_x', 'p12_y', 'p13_x',\n",
    "              'p13_y', 'p14_x', 'p14_y', 'p15_x', 'p15_y', 'p16_x', 'p16_y']\n",
    "            \n",
    "        keypoints_df = pd.DataFrame(columns=header)\n",
    "        \n",
    "        while i < df.shape[0]:\n",
    "        \n",
    "            transform = A.Compose([\n",
    "                    A.Affine(rotate=random.uniform(-0.1, 0.1), p=1),\n",
    "                    A.Affine(translate_percent={'x': random.uniform(-0.001, 0.001), 'y': random.uniform(-0.001, 0.001)}, p=1),\n",
    "                    A.Affine(shear={'x': random.uniform(-0.1, 0.1), 'y': random.uniform(-0.05, 0.05)}, p=1),\n",
    "                    A.Affine(scale=(0.999, 1.001), p=1)\n",
    "                ], keypoint_params=A.KeypointParams(format='xy'))\n",
    "            \n",
    "            image_to_be_transformed = cv2.imread(os.path.join(source_folder + '/' + f, df.iloc[i]['image_name']))\n",
    "            \n",
    "            processed_image_to_be_transformed = transform_image(image_to_be_transformed)\n",
    "            processed_image_to_be_transformed = processed_image_to_be_transformed.to(device)\n",
    "\n",
    "            keypoints = model(processed_image_to_be_transformed[None]).flatten().detach().cpu().numpy()\n",
    "            \n",
    "            x_points = keypoints[0::2]\n",
    "            y_points = keypoints[1::2]\n",
    "            x_points = x_points*image_to_be_transformed.shape[1]\n",
    "            y_points = y_points*image_to_be_transformed.shape[0]\n",
    "\n",
    "            transformed = transform(image=image_to_be_transformed, keypoints=list(zip(x_points, y_points)))\n",
    "            transformed_image = transformed['image']\n",
    "            transformed_keypoints = transformed['keypoints']\n",
    "            \n",
    "            if repeat >= 20:\n",
    "                print('skipping')\n",
    "                repeat = 0\n",
    "                i = i + 1\n",
    "                continue\n",
    "    \n",
    "            if len(transformed_keypoints) != 16:\n",
    "#                 print(df.iloc[i]['image_name'])\n",
    "                repeat = repeat + 1\n",
    "                continue\n",
    "            \n",
    "            flatten_coordinates = np.array(transformed_keypoints).flatten()\n",
    "            flatten_coordinates[::2] = [x / transformed_image.shape[1] for x in flatten_coordinates[::2]]\n",
    "            flatten_coordinates[1::2] = [x / transformed_image.shape[0] for x in flatten_coordinates[1::2]]\n",
    "            keypoints_df.loc[len(keypoints_df)] = pd.Series(flatten_coordinates, index=header)\n",
    "#             print(flatten_coordinates)\n",
    "#             print(keypoints_df)\n",
    "            \n",
    "#             transformed_image[..., [0, 2]] = transformed_image[..., [2, 0]]\n",
    "#             img = Image.fromarray(np.uint8(transformed_image))\n",
    "#             img.save(destination_folder + '/' + f + '/' + df.iloc[i]['image_name'])\n",
    "            \n",
    "#             plot_keypoints(transformed_image, flatten_coordinates)\n",
    "            \n",
    "            repeat = 0\n",
    "            i = i + 1\n",
    "        \n",
    "        complete_df = pd.concat([df, keypoints_df], axis=1)\n",
    "        complete_df.to_csv(destination_folder + '/' + f + '/' + f + '.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94758946",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_image = cv2.imread('/home/dell/Desktop/xxxx/Uni/Kirigami_project/Keypoint_detection_notebooks/Grasp_dataset_augmented/Grasp_dataset_orange/Gimage10.jpg')\n",
    "# test_keypoints = [0.12771776,0.2779994,0.47523814,0.025530297,0.8148705,0.2775899,0.8246956,0.62812585,0.49508992,0.9256545,0.15821105,0.73071223,0.43649036,0.20082472,0.40966305,0.36028758,0.39995593,0.49125895,0.41422606,0.61616457,0.44915825,0.75999326,0.52863693,0.7681227,0.5525919,0.6140371,0.5610489,0.49106207,0.5443897,0.3638414,0.51417565,0.20984803]\n",
    "# print(len(test_keypoints))\n",
    "# plot_keypoints(test_image, test_keypoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337c9168",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_datasets():\n",
    "\n",
    "    destination_folder = os.path.join(os. getcwd(), 'Grasp_dataset_augmented')\n",
    "    dataset_names = ['Grasp_dataset_orange', 'Grasp_dataset_pear', 'Grasp_dataset_banana', 'Grasp_dataset_plum', 'Grasp_dataset_egg', 'Grasp_dataset_strawberry', 'Grasp_dataset_chicken', 'Grasp_dataset_bayberry', 'Grasp_dataset_redgrape', 'Grasp_dataset_pistachio']\n",
    "\n",
    "    complete_df_set = pd.DataFrame()\n",
    "    first_dataset = True\n",
    "\n",
    "    for f in dataset_names:\n",
    "\n",
    "        df = pd.read_csv(destination_folder + '/' + f + '/' + f + '.csv')\n",
    "\n",
    "        if first_dataset == True:\n",
    "            complete_df_set = df\n",
    "            first_dataset = False\n",
    "        else:\n",
    "            complete_df_set = pd.concat([complete_df_set, df], axis=0)\n",
    "\n",
    "    complete_df_set.to_csv(destination_folder + '/' + 'Grasp_dataset_augmented.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7fd9989",
   "metadata": {},
   "outputs": [],
   "source": [
    "augment_data()\n",
    "combine_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6aa8700",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# augment_data()\n",
    "# combine_datasets()\n",
    "\n",
    "# grasp_dataset = pd.read_csv(os. getcwd() + '/' + 'Grasp_dataset_augmented/Grasp_dataset_augmented.csv')\n",
    "\n",
    "# print(grasp_dataset.tail(2))\n",
    "\n",
    "\n",
    "# data_train, data_test, label_train, label_test = train_test_split(grasp_data, grasp_label, test_size=0.2, random_state=np.random.randint(100))\n",
    "\n",
    "# clf = RandomForestClassifier(n_estimators=100, max_depth=100, random_state=np.random.randint(100))\n",
    "\n",
    "# num_folds = 10\n",
    "# cv_method = KFold(n_splits=num_folds, shuffle=True, random_state=np.random.randint(100))\n",
    "# cv_results = cross_val_score(clf, grasp_data, grasp_label, cv=cv_method, scoring='accuracy')\n",
    "\n",
    "# print('Cross-validation results:', cv_results)\n",
    "# print('Average accuracy:', cv_results.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859ae9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassifierDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        self.data, self.label = self.clean_data(df) # clean data\n",
    "        \n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        data = self.data.iloc[idx]\n",
    "        label = self.label.iloc[idx]\n",
    "#         label = F.one_hot(torch.tensor(label), 10)\n",
    "        \n",
    "        return torch.tensor(data, dtype=torch.float32).to(device), torch.tensor(label, dtype=torch.int64).to(device)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "\n",
    "\n",
    "    def clean_data(self, grasp_dataset):\n",
    "        grasp_data = grasp_dataset.drop(columns=['image_name', 'label'], axis=1)\n",
    "        grasp_data['pressure_reading_1'] = grasp_data['pressure_reading_1'] / 100\n",
    "        grasp_data['pressure_reading_2'] = grasp_data['pressure_reading_2'] / 100\n",
    "        grasp_data['force_reading_1'] = grasp_data['force_reading_1'] / 1000\n",
    "        grasp_data['force_reading_2'] = grasp_data['force_reading_2'] / 1000\n",
    "        grasp_label = grasp_dataset['label']\n",
    "\n",
    "        return grasp_data, grasp_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5841e795",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grasp_dataset = pd.read_csv(os. getcwd() + '/' + 'Grasp_dataset_augmented/Grasp_dataset_augmented.csv')\n",
    "\n",
    "# train_df, test_df = train_test_split(grasp_dataset, test_size=0.1)\n",
    "\n",
    "# train_dataset = ClassifierDataset(train_df)\n",
    "# test_dataset = ClassifierDataset(test_df)\n",
    "\n",
    "# train_dataloader = DataLoader(train_dataset, batch_size=2, shuffle=True)\n",
    "# test_dataloader = DataLoader(test_dataset, batch_size=2, shuffle=True)\n",
    "\n",
    "# for data in train_dataloader:\n",
    "#     break\n",
    "\n",
    "# input_data, target_output = data\n",
    "# print(input_data)\n",
    "# print(target_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9982fb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(16*2+4, 64),\n",
    "            nn.LeakyReLU(0.1,inplace=True),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.LeakyReLU(0.1,inplace=True),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.LeakyReLU(0.1,inplace=True),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.LeakyReLU(0.1,inplace=True),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(32, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f1bc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_model = MLP()\n",
    "classification_model = classification_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d25dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(classification_model, (8,16*2+4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4d3b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_training_set():\n",
    "\n",
    "    global train_df, test_df, train_dataset, test_dataset, train_dataloader, test_dataloader, image_data\n",
    "    \n",
    "    destination_folder = os.path.join(os. getcwd(), 'Grasp_dataset_augmented')\n",
    "\n",
    "    augment_data()\n",
    "    combine_datasets()\n",
    "    \n",
    "    grasp_dataset = pd.read_csv(os. getcwd() + '/' + 'Grasp_dataset_augmented/Grasp_dataset_augmented.csv')\n",
    "    \n",
    "    train_df, test_df = train_test_split(grasp_dataset, test_size=0.1)\n",
    "    \n",
    "    train_dataset = ClassifierDataset(train_df)\n",
    "    test_dataset = ClassifierDataset(test_df)\n",
    "    \n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=2, shuffle=True)\n",
    "    \n",
    "    print('Finished.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bfd2f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "update_training_set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3427cdab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_essentials():\n",
    "    loss_fun = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(classification_model.parameters(), lr=0.00001)\n",
    "    return loss_fun, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e672ddbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_batch(data, model, loss_fun, optimizer):\n",
    "    model.train()\n",
    "    input_data, target_output = data\n",
    "    pred_output = model(input_data)\n",
    "    loss = loss_fun(pred_output, target_output)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    return loss.item()\n",
    "\n",
    "@torch.no_grad()\n",
    "def val_batch(data, model, loss_fun, optimizer):\n",
    "    model.eval()\n",
    "    input_data, target_output = data\n",
    "    pred_output = model(input_data.to(torch.float32))\n",
    "    loss = loss_fun(pred_output, target_output)\n",
    "    return loss.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84543cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1000\n",
    "loss_fun, optimizer = get_essentials()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d274e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_epoch, val_epoch = [], []\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    train_batch_losses, val_batch_losses = [], []\n",
    "    for data in train_dataloader:\n",
    "        train_batch_loss = train_batch(data, classification_model, loss_fun, optimizer)\n",
    "        train_batch_losses.append(train_batch_loss)\n",
    "    for data in test_dataloader:\n",
    "        val_batch_loss = val_batch(data, classification_model, loss_fun, optimizer)\n",
    "        val_batch_losses.append(val_batch_loss)\n",
    "    train_epoch.append(np.mean(train_batch_losses))\n",
    "    val_epoch.append(np.mean(val_batch_losses))\n",
    "\n",
    "    if epoch % 5 == 0:\n",
    "        print(train_batch_loss, val_batch_loss)\n",
    "    \n",
    "    if (epoch) % 100 == 0:\n",
    "        torch.save(classification_model.state_dict(), './Temp_models/Model_classify_dataset_2' + str(epoch) + '_epoch')\n",
    "        update_training_set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0cb9eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(epochs), train_epoch, label=\"train_loss\")\n",
    "plt.plot(range(epochs), val_epoch, label=\"test_loss\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training Facial Keypoints model\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbac6940",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "Grasp_dataset_validation = pd.read_csv(os. getcwd() + '/' + 'Grasp_dataset_validation/Grasp_dataset_validation.csv')\n",
    "    \n",
    "\n",
    "validation_dataset = ClassifierDataset(Grasp_dataset_validation)\n",
    "    \n",
    "validation_dataloader = DataLoader(validation_dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "with torch.no_grad():\n",
    "    classification_model.eval()\n",
    "    for data in validation_dataloader:\n",
    "        input_data, labels = data\n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = classification_model(input_data)\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on the 100 test images: {100 * correct // total} %')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5530acc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e235c848",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".Keypoint_detection_notebooks",
   "language": "python",
   "name": ".keypoint_detection_notebooks"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
